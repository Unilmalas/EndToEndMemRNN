{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0056956  0.00283298 1.0056956 ]\n",
      " [0.00283298 1.0056956  1.0056956 ]\n",
      " [1.0056956  1.0056956  0.00283298]\n",
      " [1.0056956  0.00283298 1.0056956 ]]\n",
      "[[ 1.00738054 -0.00445907  1.00738054]\n",
      " [-0.00445907  1.00738054  1.00738054]\n",
      " [ 1.00738054  1.00738054 -0.00445907]\n",
      " [ 1.00738054 -0.00445907  1.00738054]]\n",
      "[[1.04046079 0.02812179 1.04046079]\n",
      " [0.02812179 1.04046079 1.04046079]\n",
      " [1.04046079 1.04046079 0.02812179]\n",
      " [1.04046079 0.02812179 1.04046079]]\n",
      "[[1.11678237 0.0192001  1.11678237]\n",
      " [0.0192001  1.11678237 1.11678237]\n",
      " [1.11678237 1.11678237 0.0192001 ]\n",
      " [1.11678237 0.0192001  1.11678237]]\n",
      "[[1.14458933 0.03843599 1.14458933]\n",
      " [0.03843599 1.14458933 1.14458933]\n",
      " [1.14458933 1.14458933 0.03843599]\n",
      " [1.14458933 0.03843599 1.14458933]]\n",
      "[[ 0.33186761 -0.75729888  0.33186761]\n",
      " [-0.75729888  0.33186761  0.33186761]\n",
      " [ 0.33186761  0.33186761 -0.75729888]\n",
      " [ 0.33186761 -0.75729888  0.33186761]]\n",
      "[[ 0.36044297 -0.71576451  0.36044297]\n",
      " [-0.71576451  0.36044297  0.36044297]\n",
      " [ 0.36044297  0.36044297 -0.71576451]\n",
      " [ 0.36044297 -0.71576451  0.36044297]]\n",
      "[[ 0.37503925 -0.70927041  0.37503925]\n",
      " [-0.70927041  0.37503925  0.37503925]\n",
      " [ 0.37503925  0.37503925 -0.70927041]\n",
      " [ 0.37503925 -0.70927041  0.37503925]]\n",
      "[[-0.24954456 -1.34757738 -0.24954456]\n",
      " [-1.34757738 -0.24954456 -0.24954456]\n",
      " [-0.24954456 -0.24954456 -1.34757738]\n",
      " [-0.24954456 -1.34757738 -0.24954456]]\n",
      "[[-0.21586805 -1.30367628 -0.21586805]\n",
      " [-1.30367628 -0.21586805 -0.21586805]\n",
      " [-0.21586805 -0.21586805 -1.30367628]\n",
      " [-0.21586805 -1.30367628 -0.21586805]]\n",
      "[[-0.20665865 -1.30739717 -0.20665865]\n",
      " [-1.30739717 -0.20665865 -0.20665865]\n",
      " [-0.20665865 -0.20665865 -1.30739717]\n",
      " [-0.20665865 -1.30739717 -0.20665865]]\n",
      "[[-0.74614235 -1.85468811 -0.74614235]\n",
      " [-1.85468811 -0.74614235 -0.74614235]\n",
      " [-0.74614235 -0.74614235 -1.85468811]\n",
      " [-0.74614235 -1.85468811 -0.74614235]]\n",
      "[[-0.68361865 -1.78130524 -0.68361865]\n",
      " [-1.78130524 -0.68361865 -0.68361865]\n",
      " [-0.68361865 -0.68361865 -1.78130524]\n",
      " [-0.68361865 -1.78130524 -0.68361865]]\n",
      "[[-1.02374439 -2.12817594 -1.02374439]\n",
      " [-2.12817594 -1.02374439 -1.02374439]\n",
      " [-1.02374439 -1.02374439 -2.12817594]\n",
      " [-1.02374439 -2.12817594 -1.02374439]]\n",
      "[[-0.93782442 -2.03707877 -0.93782442]\n",
      " [-2.03707877 -0.93782442 -0.93782442]\n",
      " [-0.93782442 -0.93782442 -2.03707877]\n",
      " [-0.93782442 -2.03707877 -0.93782442]]\n",
      "[[-1.25104849 -2.35913511 -1.25104849]\n",
      " [-2.35913511 -1.25104849 -1.25104849]\n",
      " [-1.25104849 -1.25104849 -2.35913511]\n",
      " [-1.25104849 -2.35913511 -1.25104849]]\n",
      "[[-1.13067054 -2.22552892 -1.13067054]\n",
      " [-2.22552892 -1.13067054 -1.13067054]\n",
      " [-1.13067054 -1.13067054 -2.22552892]\n",
      " [-1.13067054 -2.22552892 -1.13067054]]\n",
      "[[-1.45614557 -2.56201103 -1.45614557]\n",
      " [-2.56201103 -1.45614557 -1.45614557]\n",
      " [-1.45614557 -1.45614557 -2.56201103]\n",
      " [-1.45614557 -2.56201103 -1.45614557]]\n",
      "[[-1.33099237 -2.42667386 -1.33099237]\n",
      " [-2.42667386 -1.33099237 -1.33099237]\n",
      " [-1.33099237 -1.33099237 -2.42667386]\n",
      " [-1.33099237 -2.42667386 -1.33099237]]\n",
      "[[-1.65776108 -2.76650357 -1.65776108]\n",
      " [-2.76650357 -1.65776108 -1.65776108]\n",
      " [-1.65776108 -1.65776108 -2.76650357]\n",
      " [-1.65776108 -2.76650357 -1.65776108]]\n",
      "[[-1.49518161 -2.58571653 -1.49518161]\n",
      " [-2.58571653 -1.49518161 -1.49518161]\n",
      " [-1.49518161 -1.49518161 -2.58571653]\n",
      " [-1.49518161 -2.58571653 -1.49518161]]\n",
      "[[-1.86194748 -2.96779493 -1.86194748]\n",
      " [-2.96779493 -1.86194748 -1.86194748]\n",
      " [-1.86194748 -1.86194748 -2.96779493]\n",
      " [-1.86194748 -2.96779493 -1.86194748]]\n",
      "[[-1.68928126 -2.77874643 -1.68928126]\n",
      " [-2.77874643 -1.68928126 -1.68928126]\n",
      " [-1.68928126 -1.68928126 -2.77874643]\n",
      " [-1.68928126 -2.77874643 -1.68928126]]\n",
      "[[-2.06724384 -3.1759319  -2.06724384]\n",
      " [-3.1759319  -2.06724384 -2.06724384]\n",
      " [-2.06724384 -2.06724384 -3.1759319 ]\n",
      " [-2.06724384 -3.1759319  -2.06724384]]\n",
      "[[-1.83128159 -2.90597454 -1.83128159]\n",
      " [-2.90597454 -1.83128159 -1.83128159]\n",
      " [-1.83128159 -1.83128159 -2.90597454]\n",
      " [-1.83128159 -2.90597454 -1.83128159]]\n",
      "[[-1.74904117 -2.82100249 -1.74904117]\n",
      " [-2.82100249 -1.74904117 -1.74904117]\n",
      " [-1.74904117 -1.74904117 -2.82100249]\n",
      " [-1.74904117 -2.82100249 -1.74904117]]\n",
      "[[-1.56558831 -2.64432071 -1.56558831]\n",
      " [-2.64432071 -1.56558831 -1.56558831]\n",
      " [-1.56558831 -1.56558831 -2.64432071]\n",
      " [-1.56558831 -2.64432071 -1.56558831]]\n",
      "[[-3.01174587 -4.27000439 -3.01174587]\n",
      " [-4.27000439 -3.01174587 -3.01174587]\n",
      " [-3.01174587 -3.01174587 -4.27000439]\n",
      " [-3.01174587 -4.27000439 -3.01174587]]\n",
      "[[-2.39952379 -3.35488706 -2.39952379]\n",
      " [-3.35488706 -2.39952379 -2.39952379]\n",
      " [-2.39952379 -2.39952379 -3.35488706]\n",
      " [-2.39952379 -3.35488706 -2.39952379]]\n",
      "[[-2.45264812 -3.43165268 -2.45264812]\n",
      " [-3.43165268 -2.45264812 -2.45264812]\n",
      " [-2.45264812 -2.45264812 -3.43165268]\n",
      " [-2.45264812 -3.43165268 -2.45264812]]\n",
      "[[-2.49336512 -3.47381195 -2.49336512]\n",
      " [-3.47381195 -2.49336512 -2.49336512]\n",
      " [-2.49336512 -2.49336512 -3.47381195]\n",
      " [-2.49336512 -3.47381195 -2.49336512]]\n",
      "[[-2.52155985 -3.5103403  -2.52155985]\n",
      " [-3.5103403  -2.52155985 -2.52155985]\n",
      " [-2.52155985 -2.52155985 -3.5103403 ]\n",
      " [-2.52155985 -3.5103403  -2.52155985]]\n",
      "[[-2.55042963 -3.54987914 -2.55042963]\n",
      " [-3.54987914 -2.55042963 -2.55042963]\n",
      " [-2.55042963 -2.55042963 -3.54987914]\n",
      " [-2.55042963 -3.54987914 -2.55042963]]\n",
      "[[-2.58088474 -3.59206832 -2.58088474]\n",
      " [-3.59206832 -2.58088474 -2.58088474]\n",
      " [-2.58088474 -2.58088474 -3.59206832]\n",
      " [-2.58088474 -3.59206832 -2.58088474]]\n",
      "[[-2.60979699 -3.63230823 -2.60979699]\n",
      " [-3.63230823 -2.60979699 -2.60979699]\n",
      " [-2.60979699 -2.60979699 -3.63230823]\n",
      " [-2.60979699 -3.63230823 -2.60979699]]\n",
      "[[-2.64180177 -3.67632473 -2.64180177]\n",
      " [-3.67632473 -2.64180177 -2.64180177]\n",
      " [-2.64180177 -2.64180177 -3.67632473]\n",
      " [-2.64180177 -3.67632473 -2.64180177]]\n",
      "[[-2.67418057 -3.72089242 -2.67418057]\n",
      " [-3.72089242 -2.67418057 -2.67418057]\n",
      " [-2.67418057 -2.67418057 -3.72089242]\n",
      " [-2.67418057 -3.72089242 -2.67418057]]\n",
      "[[-2.70746059 -3.76696036 -2.70746059]\n",
      " [-3.76696036 -2.70746059 -2.70746059]\n",
      " [-2.70746059 -2.70746059 -3.76696036]\n",
      " [-2.70746059 -3.76696036 -2.70746059]]\n",
      "[[-2.7399413  -3.81194976 -2.7399413 ]\n",
      " [-3.81194976 -2.7399413  -2.7399413 ]\n",
      " [-2.7399413  -2.7399413  -3.81194976]\n",
      " [-2.7399413  -3.81194976 -2.7399413 ]]\n",
      "[[-2.77739435 -3.86305237 -2.77739435]\n",
      " [-3.86305237 -2.77739435 -2.77739435]\n",
      " [-2.77739435 -2.77739435 -3.86305237]\n",
      " [-2.77739435 -3.86305237 -2.77739435]]\n",
      "[[-2.81574284 -3.91540089 -2.81574284]\n",
      " [-3.91540089 -2.81574284 -2.81574284]\n",
      " [-2.81574284 -2.81574284 -3.91540089]\n",
      " [-2.81574284 -3.91540089 -2.81574284]]\n",
      "[[-2.85574086 -3.97031396 -2.85574086]\n",
      " [-3.97031396 -2.85574086 -2.85574086]\n",
      " [-2.85574086 -2.85574086 -3.97031396]\n",
      " [-2.85574086 -3.97031396 -2.85574086]]\n",
      "[[-2.89518132 -4.02448922 -2.89518132]\n",
      " [-4.02448922 -2.89518132 -2.89518132]\n",
      " [-2.89518132 -2.89518132 -4.02448922]\n",
      " [-2.89518132 -4.02448922 -2.89518132]]\n",
      "[[-2.94136861 -4.08697404 -2.94136861]\n",
      " [-4.08697404 -2.94136861 -2.94136861]\n",
      " [-2.94136861 -2.94136861 -4.08697404]\n",
      " [-2.94136861 -4.08697404 -2.94136861]]\n",
      "[[-2.98869887 -4.15103724 -2.98869887]\n",
      " [-4.15103724 -2.98869887 -2.98869887]\n",
      " [-2.98869887 -2.98869887 -4.15103724]\n",
      " [-2.98869887 -4.15103724 -2.98869887]]\n",
      "[[-3.03830246 -4.21859419 -3.03830246]\n",
      " [-4.21859419 -3.03830246 -3.03830246]\n",
      " [-3.03830246 -3.03830246 -4.21859419]\n",
      " [-3.03830246 -4.21859419 -3.03830246]]\n",
      "[[-3.0873976 -4.2854968 -3.0873976]\n",
      " [-4.2854968 -3.0873976 -3.0873976]\n",
      " [-3.0873976 -3.0873976 -4.2854968]\n",
      " [-3.0873976 -4.2854968 -3.0873976]]\n",
      "[[-3.14549227 -4.36347997 -3.14549227]\n",
      " [-4.36347997 -3.14549227 -3.14549227]\n",
      " [-3.14549227 -3.14549227 -4.36347997]\n",
      " [-3.14549227 -4.36347997 -3.14549227]]\n",
      "[[-3.20509052 -4.44351561 -3.20509052]\n",
      " [-4.44351561 -3.20509052 -3.20509052]\n",
      " [-3.20509052 -3.20509052 -4.44351561]\n",
      " [-3.20509052 -4.44351561 -3.20509052]]\n",
      "[[-3.26783615 -4.52833455 -3.26783615]\n",
      " [-4.52833455 -3.26783615 -3.26783615]\n",
      " [-3.26783615 -3.26783615 -4.52833455]\n",
      " [-3.26783615 -4.52833455 -3.26783615]]\n",
      "[[-3.33015329 -4.61262419 -3.33015329]\n",
      " [-4.61262419 -3.33015329 -3.33015329]\n",
      " [-3.33015329 -3.33015329 -4.61262419]\n",
      " [-3.33015329 -4.61262419 -3.33015329]]\n",
      "[[-3.40441368 -4.71161614 -3.40441368]\n",
      " [-4.71161614 -3.40441368 -3.40441368]\n",
      " [-3.40441368 -3.40441368 -4.71161614]\n",
      " [-3.40441368 -4.71161614 -3.40441368]]\n",
      "[[-3.48072999 -4.8133803  -3.48072999]\n",
      " [-4.8133803  -3.48072999 -3.48072999]\n",
      " [-3.48072999 -3.48072999 -4.8133803 ]\n",
      " [-3.48072999 -4.8133803  -3.48072999]]\n",
      "[[-3.56148051 -4.92179692 -3.56148051]\n",
      " [-4.92179692 -3.56148051 -3.56148051]\n",
      " [-3.56148051 -3.56148051 -4.92179692]\n",
      " [-3.56148051 -4.92179692 -3.56148051]]\n",
      "[[-3.64199099 -5.02995009 -3.64199099]\n",
      " [-5.02995009 -3.64199099 -3.64199099]\n",
      " [-3.64199099 -3.64199099 -5.02995009]\n",
      " [-3.64199099 -5.02995009 -3.64199099]]\n",
      "[[-3.73836105 -5.15762967 -3.73836105]\n",
      " [-5.15762967 -3.73836105 -3.73836105]\n",
      " [-3.73836105 -3.73836105 -5.15762967]\n",
      " [-3.73836105 -5.15762967 -3.73836105]]\n",
      "[[-3.83765556 -5.28920131 -3.83765556]\n",
      " [-5.28920131 -3.83765556 -3.83765556]\n",
      " [-3.83765556 -3.83765556 -5.28920131]\n",
      " [-3.83765556 -5.28920131 -3.83765556]]\n",
      "[[-3.9433283  -5.43019652 -3.9433283 ]\n",
      " [-5.43019652 -3.9433283  -3.9433283 ]\n",
      " [-3.9433283  -3.9433283  -5.43019652]\n",
      " [-3.9433283  -5.43019652 -3.9433283 ]]\n",
      "[[-4.04917378 -5.5714812  -4.04917378]\n",
      " [-5.5714812  -4.04917378 -4.04917378]\n",
      " [-4.04917378 -4.04917378 -5.5714812 ]\n",
      " [-4.04917378 -5.5714812  -4.04917378]]\n",
      "[[-4.17626873 -5.73894104 -4.17626873]\n",
      " [-5.73894104 -4.17626873 -4.17626873]\n",
      " [-4.17626873 -4.17626873 -5.73894104]\n",
      " [-4.17626873 -5.73894104 -4.17626873]]\n",
      "[[-4.3076987  -5.91208848 -4.3076987 ]\n",
      " [-5.91208848 -4.3076987  -4.3076987 ]\n",
      " [-4.3076987  -4.3076987  -5.91208848]\n",
      " [-4.3076987  -5.91208848 -4.3076987 ]]\n",
      "[[-4.4485128  -6.09885765 -4.4485128 ]\n",
      " [-6.09885765 -4.4485128  -4.4485128 ]\n",
      " [-4.4485128  -4.4485128  -6.09885765]\n",
      " [-4.4485128  -6.09885765 -4.4485128 ]]\n",
      "[[-4.59033639 -6.28700782 -4.59033639]\n",
      " [-6.28700782 -4.59033639 -4.59033639]\n",
      " [-4.59033639 -4.59033639 -6.28700782]\n",
      " [-4.59033639 -6.28700782 -4.59033639]]\n",
      "[[-4.7611509  -6.51089218 -4.7611509 ]\n",
      " [-6.51089218 -4.7611509  -4.7611509 ]\n",
      " [-4.7611509  -4.7611509  -6.51089218]\n",
      " [-4.7611509  -6.51089218 -4.7611509 ]]\n",
      "[[-4.93866548 -6.74343259 -4.93866548]\n",
      " [-6.74343259 -4.93866548 -4.93866548]\n",
      " [-4.93866548 -4.93866548 -6.74343259]\n",
      " [-4.93866548 -6.74343259 -4.93866548]]\n",
      "[[-5.13032588 -6.99610953 -5.13032588]\n",
      " [-6.99610953 -5.13032588 -5.13032588]\n",
      " [-5.13032588 -5.13032588 -6.99610953]\n",
      " [-5.13032588 -6.99610953 -5.13032588]]\n",
      "[[-5.32462062 -7.25225653 -5.32462062]\n",
      " [-7.25225653 -5.32462062 -5.32462062]\n",
      " [-5.32462062 -5.32462062 -7.25225653]\n",
      " [-5.32462062 -7.25225653 -5.32462062]]\n",
      "[[-5.55951795 -7.55847599 -5.55951795]\n",
      " [-7.55847599 -5.55951795 -5.55951795]\n",
      " [-5.55951795 -5.55951795 -7.55847599]\n",
      " [-5.55951795 -7.55847599 -5.55951795]]\n",
      "[[-5.80519292 -7.87839738 -5.80519292]\n",
      " [-7.87839738 -5.80519292 -5.80519292]\n",
      " [-5.80519292 -5.80519292 -7.87839738]\n",
      " [-5.80519292 -7.87839738 -5.80519292]]\n",
      "[[-6.07275346 -8.22883584 -6.07275346]\n",
      " [-8.22883584 -6.07275346 -6.07275346]\n",
      " [-6.07275346 -6.07275346 -8.22883584]\n",
      " [-6.07275346 -8.22883584 -6.07275346]]\n",
      "[[-6.34605207 -8.58670104 -6.34605207]\n",
      " [-8.58670104 -6.34605207 -6.34605207]\n",
      " [-6.34605207 -6.34605207 -8.58670104]\n",
      " [-6.34605207 -8.58670104 -6.34605207]]\n",
      "[[-6.67811711 -9.01703486 -6.67811711]\n",
      " [-9.01703486 -6.67811711 -6.67811711]\n",
      " [-6.67811711 -6.67811711 -9.01703486]\n",
      " [-6.67811711 -9.01703486 -6.67811711]]\n",
      "[[-7.02816171 -9.46985778 -7.02816171]\n",
      " [-9.46985778 -7.02816171 -7.02816171]\n",
      " [-7.02816171 -7.02816171 -9.46985778]\n",
      " [-7.02816171 -9.46985778 -7.02816171]]\n",
      "[[-7.41297148 -9.97015319 -7.41297148]\n",
      " [-9.97015319 -7.41297148 -7.41297148]\n",
      " [-7.41297148 -7.41297148 -9.97015319]\n",
      " [-7.41297148 -9.97015319 -7.41297148]]\n",
      "[[ -7.80945827 -10.4854053   -7.80945827]\n",
      " [-10.4854053   -7.80945827  -7.80945827]\n",
      " [ -7.80945827  -7.80945827 -10.4854053 ]\n",
      " [ -7.80945827 -10.4854053   -7.80945827]]\n",
      "[[ -8.29434777 -11.10954335  -8.29434777]\n",
      " [-11.10954335  -8.29434777  -8.29434777]\n",
      " [ -8.29434777  -8.29434777 -11.10954335]\n",
      " [ -8.29434777 -11.10954335  -8.29434777]]\n",
      "[[ -8.81009917 -11.7716606   -8.81009917]\n",
      " [-11.7716606   -8.81009917  -8.81009917]\n",
      " [ -8.81009917  -8.81009917 -11.7716606 ]\n",
      " [ -8.81009917 -11.7716606   -8.81009917]]\n",
      "[[ -9.38245477 -12.50950163  -9.38245477]\n",
      " [-12.50950163  -9.38245477  -9.38245477]\n",
      " [ -9.38245477  -9.38245477 -12.50950163]\n",
      " [ -9.38245477 -12.50950163  -9.38245477]]\n",
      "[[ -9.97799989 -13.27682055  -9.97799989]\n",
      " [-13.27682055  -9.97799989  -9.97799989]\n",
      " [ -9.97799989  -9.97799989 -13.27682055]\n",
      " [ -9.97799989 -13.27682055  -9.97799989]]\n",
      "[[-10.71238884 -14.21462939 -10.71238884]\n",
      " [-14.21462939 -10.71238884 -10.71238884]\n",
      " [-10.71238884 -10.71238884 -14.21462939]\n",
      " [-10.71238884 -14.21462939 -10.71238884]]\n"
     ]
    }
   ],
   "source": [
    "# neural turing machine with FF as controller\n",
    "# see also https://github.com/flomlo/ntm_keras\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def tanh_arr(x, d=False):\n",
    "    if d:\n",
    "        return 1 - np.tanh(x)\n",
    "    else:\n",
    "        return np.tanh(x)\n",
    "\n",
    "def siginv_arr(y, d=False): # sigmoid inversed\n",
    "    if d:\n",
    "        return 1 / y / (1 - y)\n",
    "    else:\n",
    "        return np.log( y / (1 - y) )\n",
    "\n",
    "def sig_arr(x, d=False): # sigmoid\n",
    "    if d:\n",
    "        return np.exp(-x) / (1 + np.exp(-x)) ** 2\n",
    "    else:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x, d=False):\n",
    "    ex = np.exp(x - np.max(x))\n",
    "    res = ex / ex.sum()\n",
    "    if d:\n",
    "        return res * (1 - res)\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "def simK(u, v): # similarity measure\n",
    "    return np.dot(u, v) / np.linalg.norm(u) / np.linalg.norm(v)\n",
    "\n",
    "def weights(wt, wt_1, Mt, kt, betat, gt, st, gammat):\n",
    "    nmemslots = np.shape(Mt)[0]\n",
    "    for i in range(nmemslots):\n",
    "        wt[i] = softmax(betat * simK(Mt[i], kt), False) # content addressing\n",
    "    wt = gt * wt + (1 - gt) * wt_1 # gated weighing\n",
    "    wt = np.convolve(wt, st, mode='same') # convolutional shift - todo: circular (does not make a big difference)\n",
    "    wt = (np.sign(wt) * np.abs(wt) ** gammat) / np.sum(np.sign(wt) * np.abs(wt) ** gammat) # sharpening (careful fractional powers)\n",
    "    return wt\n",
    "\n",
    "def concat(atgt, *args): # custom concat\n",
    "    res = atgt.flatten().tolist()\n",
    "    for e in args:\n",
    "        if type(e) is float:\n",
    "            res += [e]\n",
    "        elif type(e) is list:\n",
    "            res += e\n",
    "        else:\n",
    "            res += e.flatten().tolist()\n",
    "    return np.array(res)\n",
    "\n",
    "def act_fwd(hc, csplit): # activation forward pass\n",
    "    # subvectors: data + wt-1 + kt + beta + gt + st + gamma + et + at\n",
    "    # lengths in csplit: ndata + nmemslots + m_depth + 1 + 1 + 3 + 1 + 2 * nmemslots\n",
    "    # activations: ReLU + ReLU + tanh + ? + ? + soft + sig(inv, clip) + sig + tanh\n",
    "    yc, wtc, ktc, betatc, gtc, stc, gammatc, etc, atc = np.split(hc, csplit)\n",
    "    yc = np.maximum(yc, 0, yc) # ReLU\n",
    "    wtc = np.maximum(wtc, 0, wtc) # ReLU\n",
    "    ktc = tanh_arr(ktc, False)\n",
    "    betatc = np.maximum(betatc, 0, betatc) # ReLU ?\n",
    "    gtc = np.maximum(gtc, 0, gtc) # ReLU ?\n",
    "    stc = softmax(stc, False)\n",
    "    gammatc = np.clip(sig_arr(gammatc, False), -1, 1) # ?\n",
    "    etc = sig_arr(etc, False)\n",
    "    atc = tanh_arr(atc, False)\n",
    "    return concat(yc, wtc, ktc, betatc, gtc, stc, gammatc, etc, atc)\n",
    "\n",
    "def act_bck(hc, csplit): #  activation backpropagation\n",
    "    # subvectors: data + wt-1 + kt + beta + gt + st + gamma + et + at\n",
    "    # lengths in csplit: ndata + nmemslots + m_depth + 1 + 1 + 3 + 1 + 2 * nmemslots\n",
    "    # activations: ReLU + ReLU + tanh + ? + ? + soft + sig(inv, clip) + sig + tanh\n",
    "    yc, wtc, ktc, betatc, gtc, stc, gammatc, etc, atc = np.split(hc, csplit)\n",
    "    yc = ((yc > 0) * 1.) # ReLU\n",
    "    wtc = ((wtc > 0) * 1.) # ReLU\n",
    "    ktc = tanh_arr(ktc, True)\n",
    "    betatc = ((betatc > 0) * 1.) # ReLU ?\n",
    "    gtc = ((gtc > 0) * 1.) # ReLU ?\n",
    "    stc = softmax(stc, True)\n",
    "    gammatc = np.clip(sig_arr(gammatc, True), -1, 1) # ?\n",
    "    etc = sig_arr(etc, True)\n",
    "    atc = tanh_arr(atc, True)\n",
    "    return concat(yc, wtc, ktc, betatc, gtc, stc, gammatc, etc, atc)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # parameters\n",
    "    ndata = 4 # size of external input data\n",
    "    etha = 0.1 # learning rate\n",
    "    ntmstps = 20\n",
    "    \n",
    "    # fill memory\n",
    "    m_depth = 3\n",
    "    Mt = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0], [1, 0, 1]]) # memory (N slots), m_depth=3\n",
    "    nmemslots = np.shape(Mt)[0] # 4\n",
    "    wt = np.array([0.25, 0.25, 0.25, 0.25]) # weights 1-N: one for each memory entry, initial values\n",
    "    \n",
    "    # the controller vectors are (data_vector, kt, beta, gt, st, gamma)\n",
    "    kt = np.zeros((1, m_depth)) # key vector of length M (here: m_depth)\n",
    "    betat = 0.8 # key strength\n",
    "    gt = 0.5 # interpolation gate\n",
    "    st = np.array([0.1, 0.8, 0.1]) # shift weighting\n",
    "    gammat = 2.0 # sharpening\n",
    "    # length of controller vector: data + wt-1 + kt + beta + gt + st + gamma + et + at\n",
    "    nctrlvec = ndata + nmemslots + m_depth + 1 + 1 + 3 + 1 + 2 * nmemslots\n",
    "    ctrl_inpv = np.zeros((1, nctrlvec)) # input controller\n",
    "    \n",
    "    # split vector data + wt-1 + kt + beta + gt + st + gamma\n",
    "    ctrl_out_split = np.array([ndata, ndata+nmemslots, ndata+nmemslots+m_depth, ndata+nmemslots+m_depth+1, ndata+nmemslots+m_depth+2, ndata+nmemslots+m_depth+5, ndata+nmemslots+m_depth+6, ndata+nmemslots+m_depth+6+nmemslots])\n",
    "    et = np.zeros((nmemslots)) # erase vector\n",
    "    at = np.zeros((nmemslots)) # add vector\n",
    "    \n",
    "    x = np.zeros((ndata)) # input external data\n",
    "    y = np.zeros((ndata)) # output external data\n",
    "    \n",
    "    # model parameters\n",
    "    W1 = np.random.randn(nctrlvec, nctrlvec)*0.01 # input to hidden\n",
    "    W2 = np.random.randn(nctrlvec, nctrlvec)*0.01 # hidden to output\n",
    "    b1 = np.zeros((1, nctrlvec)) # inp-hidden bias\n",
    "    b2 = np.zeros((1, nctrlvec)) # hidden-out bias\n",
    "    \n",
    "    # time steps\n",
    "    for thist in range(ntmstps):\n",
    "\n",
    "        # head moves todo: add multihead\n",
    "        iheadpos = 0\n",
    "        while iheadpos < nmemslots:\n",
    "            wt_1 = wt\n",
    "\n",
    "            # old memory Mt, read-weights wt from last step: feed read-vector to controller\n",
    "            # calculate read vector to feed controller\n",
    "            # read output vector from head location\n",
    "            rt = np.dot(wt, Mt) # dim M, weighted memories\n",
    "\n",
    "            # controller runs a single step (with input from outside)\n",
    "            x = np.array([[0., 1., 0., 0.]]) # receive input vector from outside todo: really outside!\n",
    "            ctrl_inpv = concat(x, wt, kt, betat, gt, st, gammat, et, at)\n",
    "            # set indices for erase/add\n",
    "            if iheadpos > 0:\n",
    "                et[iheadpos-1] = 0\n",
    "                at[iheadpos-1] = 0\n",
    "            et[iheadpos] = 1\n",
    "            at[iheadpos] = 1\n",
    "            # controller forward pass, single step\n",
    "            h1 = np.dot(ctrl_inpv, W1) + b1\n",
    "            #h1 = np.maximum(h1, 0, h1) # ReLU todo: different by parameter\n",
    "            h1 = act_fwd(h1[0], ctrl_out_split) # forward pass (different activation by subvector)\n",
    "            o2 = np.dot(h1, W2) + b2\n",
    "            # backward pass\n",
    "            y[1] = 1. # arbitrary external output data (truth), todo: check, what is the entire truth?\n",
    "            ctrl_outv = concat(y, wt, kt, betat, gt, st, gammat, et, at)\n",
    "            #dW1 = - etha * (o2 - ctrl_outv) * np.maximum(h1, 0, h1)\n",
    "            dW1 = - etha * (o2 - ctrl_outv) * h1\n",
    "            dW2 = dW1 * act_bck(h1, ctrl_out_split) * ctrl_inpv\n",
    "            W1 += dW1\n",
    "            W2 += dW2\n",
    "\n",
    "            # controller unactivated output divided into actual data output, reading, writing instructions\n",
    "            # split: output_dim, read_heads, write_heads\n",
    "            # split and apply activations:\n",
    "            # k and add_vector are activated via tanh, erase_vector via sigmoid (this is critical!),\n",
    "            # shift via softmax, gamma is sigmoided, inversed and clipped (probably not ideal)\n",
    "            # g is sigmoided, beta is linear (probably not ideal!)\n",
    "            y, wt, kt, betat, gt, st, gammat, et, at = np.split(o2[0], ctrl_out_split)\n",
    "\n",
    "            # write memory for each head: calculate weights, erase, add\n",
    "            wt = weights(wt, wt_1, Mt, kt, betat, gt, st, gammat)\n",
    "            Mt = Mt - Mt * np.dot(wt, et.T) # erase\n",
    "            Mt = Mt + np.dot(wt, at.T) # add\n",
    "\n",
    "            # calculate read weights, save in the state and use for next round\n",
    "            # todo\n",
    "            iheadpos += 1\n",
    "            \n",
    "            print(Mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "[94, 49, 73, 128, 174, 45, 45, 198, 156, 2]\n",
      "[[1, 1, 1, 0, 0, 1, 1, 0], [1, 1, 1, 0, 1, 1, 0, 0], [0, 1, 0, 0, 0, 1, 1, 1], [1, 1, 1, 0, 1, 1, 1, 1], [0, 1, 0, 1, 1, 1, 1, 1], [0, 0, 1, 0, 0, 1, 0, 0], [1, 1, 1, 0, 1, 1, 1, 0], [1, 0, 1, 1, 0, 0, 1, 0], [1, 0, 1, 1, 0, 1, 0, 1], [0, 0, 1, 1, 1, 1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def rdbinseq(l): # random sequence of 8-bit binary vectors (int 0-255)\n",
    "    if l <= 0:\n",
    "        return []\n",
    "    res = []\n",
    "    for i in range(l):\n",
    "        res.append(random.randint(0, 255))\n",
    "    return res\n",
    "\n",
    "def rdbinseqb(n, l): # random sequence of n-bit binary vectors\n",
    "    if l <= 0:\n",
    "        return []\n",
    "    res = []\n",
    "    for i in range(l):\n",
    "        res.append([random.randint(0, 1) for j in range(n)])\n",
    "    return res\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    print(int('11111111', 2))\n",
    "    print(rdbinseq(10))\n",
    "    print(rdbinseqb(8, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [1 1 0]\n",
      " [0 1 1]\n",
      " [1 1 0]]\n",
      "[[0.00282289 0.00282289 1.01358598]\n",
      " [1.01358598 1.01358598 0.00282289]\n",
      " [0.00282289 1.01358598 1.01358598]\n",
      " [1.01358598 1.01358598 0.00282289]]\n",
      "[[0.00602052 0.00602052 1.0282275 ]\n",
      " [1.0282275  1.0282275  0.00602052]\n",
      " [0.00602052 1.0282275  1.0282275 ]\n",
      " [1.0282275  1.0282275  0.00602052]]\n",
      "[[0.00931985 0.00931985 1.04338309]\n",
      " [1.04338309 1.04338309 0.00931985]\n",
      " [0.00931985 1.04338309 1.04338309]\n",
      " [1.04338309 1.04338309 0.00931985]]\n",
      "[[0.01277678 0.01277678 1.05912542]\n",
      " [1.05912542 1.05912542 0.01277678]\n",
      " [0.01277678 1.05912542 1.05912542]\n",
      " [1.05912542 1.05912542 0.01277678]]\n",
      "[[0.01602008 0.01602008 1.075015  ]\n",
      " [1.075015   1.075015   0.01602008]\n",
      " [0.01602008 1.075015   1.075015  ]\n",
      " [1.075015   1.075015   0.01602008]]\n",
      "[[0.0194627  0.0194627  1.09139499]\n",
      " [1.09139499 1.09139499 0.0194627 ]\n",
      " [0.0194627  1.09139499 1.09139499]\n",
      " [1.09139499 1.09139499 0.0194627 ]]\n",
      "[[0.02302059 0.02302059 1.10845757]\n",
      " [1.10845757 1.10845757 0.02302059]\n",
      " [0.02302059 1.10845757 1.10845757]\n",
      " [1.10845757 1.10845757 0.02302059]]\n",
      "[[0.02674947 0.02674947 1.12622947]\n",
      " [1.12622947 1.12622947 0.02674947]\n",
      " [0.02674947 1.12622947 1.12622947]\n",
      " [1.12622947 1.12622947 0.02674947]]\n",
      "[[0.03026163 0.03026163 1.14424851]\n",
      " [1.14424851 1.14424851 0.03026163]\n",
      " [0.03026163 1.14424851 1.14424851]\n",
      " [1.14424851 1.14424851 0.03026163]]\n",
      "[[0.03398805 0.03398805 1.16287234]\n",
      " [1.16287234 1.16287234 0.03398805]\n",
      " [0.03398805 1.16287234 1.16287234]\n",
      " [1.16287234 1.16287234 0.03398805]]\n",
      "[[0.03784865 0.03784865 1.18236544]\n",
      " [1.18236544 1.18236544 0.03784865]\n",
      " [0.03784865 1.18236544 1.18236544]\n",
      " [1.18236544 1.18236544 0.03784865]]\n",
      "[[0.04189587 0.04189587 1.20274215]\n",
      " [1.20274215 1.20274215 0.04189587]\n",
      " [0.04189587 1.20274215 1.20274215]\n",
      " [1.20274215 1.20274215 0.04189587]]\n",
      "[[0.04572877 0.04572877 1.22351759]\n",
      " [1.22351759 1.22351759 0.04572877]\n",
      " [0.04572877 1.22351759 1.22351759]\n",
      " [1.22351759 1.22351759 0.04572877]]\n",
      "[[0.04979347 0.04979347 1.24506521]\n",
      " [1.24506521 1.24506521 0.04979347]\n",
      " [0.04979347 1.24506521 1.24506521]\n",
      " [1.24506521 1.24506521 0.04979347]]\n",
      "[[0.05401837 0.05401837 1.26774626]\n",
      " [1.26774626 1.26774626 0.05401837]\n",
      " [0.05401837 1.26774626 1.26774626]\n",
      " [1.26774626 1.26774626 0.05401837]]\n",
      "[[0.05844971 0.05844971 1.29155614]\n",
      " [1.29155614 1.29155614 0.05844971]\n",
      " [0.05844971 1.29155614 1.29155614]\n",
      " [1.29155614 1.29155614 0.05844971]]\n",
      "[[0.06267875 0.06267875 1.31597061]\n",
      " [1.31597061 1.31597061 0.06267875]\n",
      " [0.06267875 1.31597061 1.31597061]\n",
      " [1.31597061 1.31597061 0.06267875]]\n",
      "[[0.0671632  0.0671632  1.34137405]\n",
      " [1.34137405 1.34137405 0.0671632 ]\n",
      " [0.0671632  1.34137405 1.34137405]\n",
      " [1.34137405 1.34137405 0.0671632 ]]\n",
      "[[0.07184612 0.07184612 1.36824621]\n",
      " [1.36824621 1.36824621 0.07184612]\n",
      " [0.07184612 1.36824621 1.36824621]\n",
      " [1.36824621 1.36824621 0.07184612]]\n",
      "[[0.0767632  0.0767632  1.39654445]\n",
      " [1.39654445 1.39654445 0.0767632 ]\n",
      " [0.0767632  1.39654445 1.39654445]\n",
      " [1.39654445 1.39654445 0.0767632 ]]\n",
      "[[0.0815039  0.0815039  1.42567081]\n",
      " [1.42567081 1.42567081 0.0815039 ]\n",
      " [0.0815039  1.42567081 1.42567081]\n",
      " [1.42567081 1.42567081 0.0815039 ]]\n",
      "[[0.08653174 0.08653174 1.45601169]\n",
      " [1.45601169 1.45601169 0.08653174]\n",
      " [0.08653174 1.45601169 1.45601169]\n",
      " [1.45601169 1.45601169 0.08653174]]\n",
      "[[0.09181146 0.09181146 1.48819981]\n",
      " [1.48819981 1.48819981 0.09181146]\n",
      " [0.09181146 1.48819981 1.48819981]\n",
      " [1.48819981 1.48819981 0.09181146]]\n",
      "[[0.09736032 0.09736032 1.52213433]\n",
      " [1.52213433 1.52213433 0.09736032]\n",
      " [0.09736032 1.52213433 1.52213433]\n",
      " [1.52213433 1.52213433 0.09736032]]\n",
      "[[0.10277247 0.10277247 1.55713711]\n",
      " [1.55713711 1.55713711 0.10277247]\n",
      " [0.10277247 1.55713711 1.55713711]\n",
      " [1.55713711 1.55713711 0.10277247]]\n",
      "[[0.1085095  0.1085095  1.59360261]\n",
      " [1.59360261 1.59360261 0.1085095 ]\n",
      " [0.1085095  1.59360261 1.59360261]\n",
      " [1.59360261 1.59360261 0.1085095 ]]\n",
      "[[0.11456783 0.11456783 1.63239394]\n",
      " [1.63239394 1.63239394 0.11456783]\n",
      " [0.11456783 1.63239394 1.63239394]\n",
      " [1.63239394 1.63239394 0.11456783]]\n",
      "[[0.12093519 0.12093519 1.67333053]\n",
      " [1.67333053 1.67333053 0.12093519]\n",
      " [0.12093519 1.67333053 1.67333053]\n",
      " [1.67333053 1.67333053 0.12093519]]\n",
      "[[0.12722094 0.12722094 1.71568334]\n",
      " [1.71568334 1.71568334 0.12722094]\n",
      " [0.12722094 1.71568334 1.71568334]\n",
      " [1.71568334 1.71568334 0.12722094]]\n",
      "[[0.13387719 0.13387719 1.7598544 ]\n",
      " [1.7598544  1.7598544  0.13387719]\n",
      " [0.13387719 1.7598544  1.7598544 ]\n",
      " [1.7598544  1.7598544  0.13387719]]\n",
      "[[0.14094786 0.14094786 1.80704024]\n",
      " [1.80704024 1.80704024 0.14094786]\n",
      " [0.14094786 1.80704024 1.80704024]\n",
      " [1.80704024 1.80704024 0.14094786]]\n",
      "[[0.14837661 0.14837661 1.8569332 ]\n",
      " [1.8569332  1.8569332  0.14837661]\n",
      " [0.14837661 1.8569332  1.8569332 ]\n",
      " [1.8569332  1.8569332  0.14837661]]\n",
      "[[0.15580169 0.15580169 1.90877435]\n",
      " [1.90877435 1.90877435 0.15580169]\n",
      " [0.15580169 1.90877435 1.90877435]\n",
      " [1.90877435 1.90877435 0.15580169]]\n",
      "[[0.16365833 0.16365833 1.96296119]\n",
      " [1.96296119 1.96296119 0.16365833]\n",
      " [0.16365833 1.96296119 1.96296119]\n",
      " [1.96296119 1.96296119 0.16365833]]\n",
      "[[0.17206003 0.17206003 2.02116028]\n",
      " [2.02116028 2.02116028 0.17206003]\n",
      " [0.17206003 2.02116028 2.02116028]\n",
      " [2.02116028 2.02116028 0.17206003]]\n",
      "[[0.18088697 0.18088697 2.08287028]\n",
      " [2.08287028 2.08287028 0.18088697]\n",
      " [0.18088697 2.08287028 2.08287028]\n",
      " [2.08287028 2.08287028 0.18088697]]\n",
      "[[0.18982083 0.18982083 2.14730824]\n",
      " [2.14730824 2.14730824 0.18982083]\n",
      " [0.18982083 2.14730824 2.14730824]\n",
      " [2.14730824 2.14730824 0.18982083]]\n",
      "[[0.19927313 0.19927313 2.21485997]\n",
      " [2.21485997 2.21485997 0.19927313]\n",
      " [0.19927313 2.21485997 2.21485997]\n",
      " [2.21485997 2.21485997 0.19927313]]\n",
      "[[0.20945838 0.20945838 2.28786676]\n",
      " [2.28786676 2.28786676 0.20945838]\n",
      " [0.20945838 2.28786676 2.28786676]\n",
      " [2.28786676 2.28786676 0.20945838]]\n",
      "[[0.22016728 0.22016728 2.36554906]\n",
      " [2.36554906 2.36554906 0.22016728]\n",
      " [0.22016728 2.36554906 2.36554906]\n",
      " [2.36554906 2.36554906 0.22016728]]\n",
      "[[0.23113999 0.23113999 2.44709328]\n",
      " [2.44709328 2.44709328 0.23113999]\n",
      " [0.23113999 2.44709328 2.44709328]\n",
      " [2.44709328 2.44709328 0.23113999]]\n",
      "[[0.24275892 0.24275892 2.53287621]\n",
      " [2.53287621 2.53287621 0.24275892]\n",
      " [0.24275892 2.53287621 2.53287621]\n",
      " [2.53287621 2.53287621 0.24275892]]\n",
      "[[0.2553863  0.2553863  2.62623171]\n",
      " [2.62623171 2.62623171 0.2553863 ]\n",
      " [0.2553863  2.62623171 2.62623171]\n",
      " [2.62623171 2.62623171 0.2553863 ]]\n",
      "[[0.26868866 0.26868866 2.72599012]\n",
      " [2.72599012 2.72599012 0.26868866]\n",
      " [0.26868866 2.72599012 2.72599012]\n",
      " [2.72599012 2.72599012 0.26868866]]\n",
      "[[0.28247962 0.28247962 2.83128444]\n",
      " [2.83128444 2.83128444 0.28247962]\n",
      " [0.28247962 2.83128444 2.83128444]\n",
      " [2.83128444 2.83128444 0.28247962]]\n",
      "[[0.29710974 0.29710974 2.94249801]\n",
      " [2.94249801 2.94249801 0.29710974]\n",
      " [0.29710974 2.94249801 2.94249801]\n",
      " [2.94249801 2.94249801 0.29710974]]\n",
      "[[0.3131607  0.3131607  3.06446308]\n",
      " [3.06446308 3.06446308 0.3131607 ]\n",
      " [0.3131607  3.06446308 3.06446308]\n",
      " [3.06446308 3.06446308 0.3131607 ]]\n",
      "[[0.33012833 0.33012833 3.19546788]\n",
      " [3.19546788 3.19546788 0.33012833]\n",
      " [0.33012833 3.19546788 3.19546788]\n",
      " [3.19546788 3.19546788 0.33012833]]\n",
      "[[0.34791418 0.34791418 3.33454368]\n",
      " [3.33454368 3.33454368 0.34791418]\n",
      " [0.34791418 3.33454368 3.33454368]\n",
      " [3.33454368 3.33454368 0.34791418]]\n",
      "[[0.36683797 0.36683797 3.48211672]\n",
      " [3.48211672 3.48211672 0.36683797]\n",
      " [0.36683797 3.48211672 3.48211672]\n",
      " [3.48211672 3.48211672 0.36683797]]\n",
      "[[0.38781494 0.38781494 3.64534693]\n",
      " [3.64534693 3.64534693 0.38781494]\n",
      " [0.38781494 3.64534693 3.64534693]\n",
      " [3.64534693 3.64534693 0.38781494]]\n",
      "[[0.41010756 0.41010756 3.82177227]\n",
      " [3.82177227 3.82177227 0.41010756]\n",
      " [0.41010756 3.82177227 3.82177227]\n",
      " [3.82177227 3.82177227 0.41010756]]\n",
      "[[0.43371837 0.43371837 4.01023239]\n",
      " [4.01023239 4.01023239 0.43371837]\n",
      " [0.43371837 4.01023239 4.01023239]\n",
      " [4.01023239 4.01023239 0.43371837]]\n",
      "[[0.4589432  0.4589432  4.21127142]\n",
      " [4.21127142 4.21127142 0.4589432 ]\n",
      " [0.4589432  4.21127142 4.21127142]\n",
      " [4.21127142 4.21127142 0.4589432 ]]\n",
      "[[0.48721877 0.48721877 4.43578345]\n",
      " [4.43578345 4.43578345 0.48721877]\n",
      " [0.48721877 4.43578345 4.43578345]\n",
      " [4.43578345 4.43578345 0.48721877]]\n",
      "[[0.51749007 0.51749007 4.6802725 ]\n",
      " [4.6802725  4.6802725  0.51749007]\n",
      " [0.51749007 4.6802725  4.6802725 ]\n",
      " [4.6802725  4.6802725  0.51749007]]\n",
      "[[0.54987081 0.54987081 4.94322957]\n",
      " [4.94322957 4.94322957 0.54987081]\n",
      " [0.54987081 4.94322957 4.94322957]\n",
      " [4.94322957 4.94322957 0.54987081]]\n",
      "[[0.58465041 0.58465041 5.22547123]\n",
      " [5.22547123 5.22547123 0.58465041]\n",
      " [0.58465041 5.22547123 5.22547123]\n",
      " [5.22547123 5.22547123 0.58465041]]\n",
      "[[0.62410873 0.62410873 5.5441028 ]\n",
      " [5.5441028  5.5441028  0.62410873]\n",
      " [0.62410873 5.5441028  5.5441028 ]\n",
      " [5.5441028  5.5441028  0.62410873]]\n",
      "[[0.66676209 0.66676209 5.89421874]\n",
      " [5.89421874 5.89421874 0.66676209]\n",
      " [0.66676209 5.89421874 5.89421874]\n",
      " [5.89421874 5.89421874 0.66676209]]\n",
      "[[0.7128399  0.7128399  6.27369847]\n",
      " [6.27369847 6.27369847 0.7128399 ]\n",
      " [0.7128399  6.27369847 6.27369847]\n",
      " [6.27369847 6.27369847 0.7128399 ]]\n",
      "[[0.76266459 0.76266459 6.68396267]\n",
      " [6.68396267 6.68396267 0.76266459]\n",
      " [0.76266459 6.68396267 6.68396267]\n",
      " [6.68396267 6.68396267 0.76266459]]\n",
      "[[0.81993466 0.81993466 7.15288185]\n",
      " [7.15288185 7.15288185 0.81993466]\n",
      " [0.81993466 7.15288185 7.15288185]\n",
      " [7.15288185 7.15288185 0.81993466]]\n",
      "[[0.88259694 0.88259694 7.67368326]\n",
      " [7.67368326 7.67368326 0.88259694]\n",
      " [0.88259694 7.67368326 7.67368326]\n",
      " [7.67368326 7.67368326 0.88259694]]\n",
      "[[0.95099123 0.95099123 8.24321734]\n",
      " [8.24321734 8.24321734 0.95099123]\n",
      " [0.95099123 8.24321734 8.24321734]\n",
      " [8.24321734 8.24321734 0.95099123]]\n",
      "[[1.02556341 1.02556341 8.86426249]\n",
      " [8.86426249 8.86426249 1.02556341]\n",
      " [1.02556341 8.86426249 8.86426249]\n",
      " [8.86426249 8.86426249 1.02556341]]\n",
      "[[1.11251562 1.11251562 9.58424962]\n",
      " [9.58424962 9.58424962 1.11251562]\n",
      " [1.11251562 9.58424962 9.58424962]\n",
      " [9.58424962 9.58424962 1.11251562]]\n",
      "[[ 1.20906594  1.20906594 10.39412024]\n",
      " [10.39412024 10.39412024  1.20906594]\n",
      " [ 1.20906594 10.39412024 10.39412024]\n",
      " [10.39412024 10.39412024  1.20906594]]\n",
      "[[ 1.31564765  1.31564765 11.28910242]\n",
      " [11.28910242 11.28910242  1.31564765]\n",
      " [ 1.31564765 11.28910242 11.28910242]\n",
      " [11.28910242 11.28910242  1.31564765]]\n",
      "[[ 1.43304878  1.43304878 12.2751566 ]\n",
      " [12.2751566  12.2751566   1.43304878]\n",
      " [ 1.43304878 12.2751566  12.2751566 ]\n",
      " [12.2751566  12.2751566   1.43304878]]\n",
      "[[ 1.57215094  1.57215094 13.43726078]\n",
      " [13.43726078 13.43726078  1.57215094]\n",
      " [ 1.57215094 13.43726078 13.43726078]\n",
      " [13.43726078 13.43726078  1.57215094]]\n",
      "[[ 1.72932699  1.72932699 14.76421932]\n",
      " [14.76421932 14.76421932  1.72932699]\n",
      " [ 1.72932699 14.76421932 14.76421932]\n",
      " [14.76421932 14.76421932  1.72932699]]\n",
      "[[ 1.90509514  1.90509514 16.24904975]\n",
      " [16.24904975 16.24904975  1.90509514]\n",
      " [ 1.90509514 16.24904975 16.24904975]\n",
      " [16.24904975 16.24904975  1.90509514]]\n",
      "[[ 2.10114928  2.10114928 17.90561501]\n",
      " [17.90561501 17.90561501  2.10114928]\n",
      " [ 2.10114928 17.90561501 17.90561501]\n",
      " [17.90561501 17.90561501  2.10114928]]\n",
      "[[ 2.33774202  2.33774202 19.89577585]\n",
      " [19.89577585 19.89577585  2.33774202]\n",
      " [ 2.33774202 19.89577585 19.89577585]\n",
      " [19.89577585 19.89577585  2.33774202]]\n",
      "[[ 2.6105645   2.6105645  22.20890803]\n",
      " [22.20890803 22.20890803  2.6105645 ]\n",
      " [ 2.6105645  22.20890803 22.20890803]\n",
      " [22.20890803 22.20890803  2.6105645 ]]\n",
      "[[ 2.92034571  2.92034571 24.83634454]\n",
      " [24.83634454 24.83634454  2.92034571]\n",
      " [ 2.92034571 24.83634454 24.83634454]\n",
      " [24.83634454 24.83634454  2.92034571]]\n",
      "[[ 3.27124348  3.27124348 27.81297148]\n",
      " [27.81297148 27.81297148  3.27124348]\n",
      " [ 3.27124348 27.81297148 27.81297148]\n",
      " [27.81297148 27.81297148  3.27124348]]\n",
      "[[ 3.70388941  3.70388941 31.47063975]\n",
      " [31.47063975 31.47063975  3.70388941]\n",
      " [ 3.70388941 31.47063975 31.47063975]\n",
      " [31.47063975 31.47063975  3.70388941]]\n",
      "[[ 4.21461957  4.21461957 35.81201775]\n",
      " [35.81201775 35.81201775  4.21461957]\n",
      " [ 4.21461957 35.81201775 35.81201775]\n",
      " [35.81201775 35.81201775  4.21461957]]\n"
     ]
    }
   ],
   "source": [
    "# neural turing machine with FF as controller\n",
    "# copy task\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def rdbinseqb(n, l): # random sequence of n-bit binary vectors\n",
    "    if l <= 0:\n",
    "        return []\n",
    "    res = []\n",
    "    for i in range(l):\n",
    "        res.append([random.randint(0, 1) for j in range(n)])\n",
    "    return res\n",
    "\n",
    "def tanh_arr(x, d=False):\n",
    "    if d:\n",
    "        return 1 - np.tanh(x)\n",
    "    else:\n",
    "        return np.tanh(x)\n",
    "\n",
    "def siginv_arr(y, d=False): # sigmoid inversed\n",
    "    if d:\n",
    "        return 1 / y / (1 - y)\n",
    "    else:\n",
    "        return np.log( y / (1 - y) )\n",
    "\n",
    "def sig_arr(x, d=False): # sigmoid\n",
    "    if d:\n",
    "        return np.exp(-x) / (1 + np.exp(-x)) ** 2\n",
    "    else:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x, d=False):\n",
    "    ex = np.exp(x - np.max(x))\n",
    "    res = ex / ex.sum()\n",
    "    if d:\n",
    "        return res * (1 - res)\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "def simK(u, v): # similarity measure\n",
    "    return np.dot(u, v) / np.linalg.norm(u) / np.linalg.norm(v)\n",
    "\n",
    "def weights(wt, wt_1, Mt, kt, betat, gt, st, gammat):\n",
    "    nmemslots = np.shape(Mt)[0]\n",
    "    for i in range(nmemslots):\n",
    "        wt[i] = softmax(betat * simK(Mt[i], kt), False) # content addressing\n",
    "    wt = gt * wt + (1 - gt) * wt_1 # gated weighing\n",
    "    wt = np.convolve(wt, st, mode='same') # convolutional shift - todo: circular (does not make a big difference)\n",
    "    wt = (np.sign(wt) * np.abs(wt) ** gammat) / np.sum(np.sign(wt) * np.abs(wt) ** gammat) # sharpening (careful fractional powers)\n",
    "    return wt\n",
    "\n",
    "def concat(atgt, *args): # custom concat\n",
    "    res = atgt.flatten().tolist()\n",
    "    for e in args:\n",
    "        if type(e) is float:\n",
    "            res += [e]\n",
    "        elif type(e) is list:\n",
    "            res += e\n",
    "        else:\n",
    "            res += e.flatten().tolist()\n",
    "    return np.array(res)\n",
    "\n",
    "def act_fwd(hc, csplit): # activation forward pass\n",
    "    # subvectors: data + wt-1 + kt + beta + gt + st + gamma + et + at\n",
    "    # lengths in csplit: ndata + nmemslots + m_depth + 1 + 1 + 3 + 1 + 2 * nmemslots\n",
    "    # activations: ReLU + ReLU + tanh + ? + ? + soft + sig(inv, clip) + sig + tanh\n",
    "    yc, wtc, ktc, betatc, gtc, stc, gammatc, etc, atc = np.split(hc, csplit)\n",
    "    yc = np.maximum(yc, 0, yc) # ReLU\n",
    "    wtc = np.maximum(wtc, 0, wtc) # ReLU\n",
    "    ktc = tanh_arr(ktc, False)\n",
    "    betatc = np.maximum(betatc, 0, betatc) # ReLU ?\n",
    "    gtc = np.maximum(gtc, 0, gtc) # ReLU ?\n",
    "    stc = softmax(stc, False)\n",
    "    gammatc = np.clip(sig_arr(gammatc, False), -1, 1) # ?\n",
    "    etc = sig_arr(etc, False)\n",
    "    atc = tanh_arr(atc, False)\n",
    "    return concat(yc, wtc, ktc, betatc, gtc, stc, gammatc, etc, atc)\n",
    "\n",
    "def act_bck(hc, csplit): #  activation backpropagation\n",
    "    # subvectors: data + wt-1 + kt + beta + gt + st + gamma + et + at\n",
    "    # lengths in csplit: ndata + nmemslots + m_depth + 1 + 1 + 3 + 1 + 2 * nmemslots\n",
    "    # activations: ReLU + ReLU + tanh + ? + ? + soft + sig(inv, clip) + sig + tanh\n",
    "    yc, wtc, ktc, betatc, gtc, stc, gammatc, etc, atc = np.split(hc, csplit)\n",
    "    yc = ((yc > 0) * 1.) # ReLU\n",
    "    wtc = ((wtc > 0) * 1.) # ReLU\n",
    "    ktc = tanh_arr(ktc, True)\n",
    "    betatc = ((betatc > 0) * 1.) # ReLU ?\n",
    "    gtc = ((gtc > 0) * 1.) # ReLU ?\n",
    "    stc = softmax(stc, True)\n",
    "    gammatc = np.clip(sig_arr(gammatc, True), -1, 1) # ?\n",
    "    etc = sig_arr(etc, True)\n",
    "    atc = tanh_arr(atc, True)\n",
    "    return concat(yc, wtc, ktc, betatc, gtc, stc, gammatc, etc, atc)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # parameters\n",
    "    ndata = 4 # size of external input data\n",
    "    etha = 0.1 # learning rate\n",
    "    ntmstps = 20\n",
    "    \n",
    "    # fill memory\n",
    "    m_depth = 3\n",
    "    #Mt = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0], [1, 0, 1]]) # memory (N slots), m_depth=3\n",
    "    Mt = np.array(rdbinseqb(3, 4))\n",
    "    print(Mt)\n",
    "    nmemslots = np.shape(Mt)[0] # 4\n",
    "    wt = np.array([0.25, 0.25, 0.25, 0.25]) # weights 1-N: one for each memory entry, initial values\n",
    "    \n",
    "    # the controller vectors are (data_vector, kt, beta, gt, st, gamma)\n",
    "    kt = np.zeros((1, m_depth)) # key vector of length M (here: m_depth)\n",
    "    betat = 0.8 # key strength\n",
    "    gt = 0.5 # interpolation gate\n",
    "    st = np.array([0.1, 0.8, 0.1]) # shift weighting\n",
    "    gammat = 2.0 # sharpening\n",
    "    # length of controller vector: data + wt-1 + kt + beta + gt + st + gamma + et + at\n",
    "    nctrlvec = ndata + nmemslots + m_depth + 1 + 1 + 3 + 1 + 2 * nmemslots\n",
    "    ctrl_inpv = np.zeros((1, nctrlvec)) # input controller\n",
    "    \n",
    "    # split vector data + wt-1 + kt + beta + gt + st + gamma\n",
    "    ctrl_out_split = np.array([ndata, ndata+nmemslots, ndata+nmemslots+m_depth, ndata+nmemslots+m_depth+1, ndata+nmemslots+m_depth+2, ndata+nmemslots+m_depth+5, ndata+nmemslots+m_depth+6, ndata+nmemslots+m_depth+6+nmemslots])\n",
    "    et = np.zeros((nmemslots)) # erase vector\n",
    "    at = np.zeros((nmemslots)) # add vector\n",
    "    \n",
    "    x = np.zeros((ndata)) # input external data\n",
    "    y = np.zeros((ndata)) # output external data\n",
    "    \n",
    "    # model parameters\n",
    "    W1 = np.random.randn(nctrlvec, nctrlvec)*0.01 # input to hidden\n",
    "    W2 = np.random.randn(nctrlvec, nctrlvec)*0.01 # hidden to output\n",
    "    b1 = np.zeros((1, nctrlvec)) # inp-hidden bias\n",
    "    b2 = np.zeros((1, nctrlvec)) # hidden-out bias\n",
    "    \n",
    "    # time steps\n",
    "    for thist in range(ntmstps):\n",
    "\n",
    "        # head moves todo: add multihead\n",
    "        iheadpos = 0\n",
    "        while iheadpos < nmemslots:\n",
    "            wt_1 = wt\n",
    "\n",
    "            # old memory Mt, read-weights wt from last step: feed read-vector to controller\n",
    "            # calculate read vector to feed controller\n",
    "            # read output vector from head location\n",
    "            rt = np.dot(wt, Mt) # dim M, weighted memories\n",
    "\n",
    "            # controller runs a single step (with input from outside)\n",
    "            x = np.array([[0., 1., 0., 0.]]) # receive input vector from outside todo: really outside!\n",
    "            ctrl_inpv = concat(x, wt, kt, betat, gt, st, gammat, et, at)\n",
    "            # set indices for erase/add\n",
    "            if iheadpos > 0:\n",
    "                et[iheadpos-1] = 0\n",
    "                at[iheadpos-1] = 0\n",
    "            et[iheadpos] = 1\n",
    "            at[iheadpos] = 1\n",
    "            # controller forward pass, single step\n",
    "            h1 = np.dot(ctrl_inpv, W1) + b1\n",
    "            #h1 = np.maximum(h1, 0, h1) # ReLU todo: different by parameter\n",
    "            h1 = act_fwd(h1[0], ctrl_out_split) # forward pass (different activation by subvector)\n",
    "            o2 = np.dot(h1, W2) + b2\n",
    "            # backward pass\n",
    "            y[1] = 1. # arbitrary external output data (truth), todo: check, what is the entire truth?\n",
    "            ctrl_outv = concat(y, wt, kt, betat, gt, st, gammat, et, at)\n",
    "            #dW1 = - etha * (o2 - ctrl_outv) * np.maximum(h1, 0, h1)\n",
    "            dW1 = - etha * (o2 - ctrl_outv) * h1\n",
    "            dW2 = dW1 * act_bck(h1, ctrl_out_split) * ctrl_inpv\n",
    "            W1 += dW1\n",
    "            W2 += dW2\n",
    "\n",
    "            # controller unactivated output divided into actual data output, reading, writing instructions\n",
    "            # split: output_dim, read_heads, write_heads\n",
    "            # split and apply activations:\n",
    "            # k and add_vector are activated via tanh, erase_vector via sigmoid (this is critical!),\n",
    "            # shift via softmax, gamma is sigmoided, inversed and clipped (probably not ideal)\n",
    "            # g is sigmoided, beta is linear (probably not ideal!)\n",
    "            y, wt, kt, betat, gt, st, gammat, et, at = np.split(o2[0], ctrl_out_split)\n",
    "\n",
    "            # write memory for each head: calculate weights, erase, add\n",
    "            wt = weights(wt, wt_1, Mt, kt, betat, gt, st, gammat)\n",
    "            Mt = Mt - Mt * np.dot(wt, et.T) # erase\n",
    "            Mt = Mt + np.dot(wt, at.T) # add\n",
    "\n",
    "            # calculate read weights, save in the state and use for next round\n",
    "            # todo\n",
    "            iheadpos += 1\n",
    "            \n",
    "            print(Mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
