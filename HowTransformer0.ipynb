{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to code the Transformer\n",
    "\n",
    "from Samuel Lynn-Evans (adapted, still work in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding and Positional Encoding\n",
    "\n",
    "each word is fed into the network, this code will perform a look-up and retrieve its embedding vector. These vectors will then be learnt as a parameters by the model\n",
    "\n",
    "The embedding vector for each word will learn the meaning, so now we need to input something that tells the network about the word’s position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embed = nn.Embedding(vocab_size, d_model) # look up table from indices to vectors\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 200, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout) # randomly zeroes some of the elements of the input tensor with probability p\n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        # add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        pe = Variable(self.pe[:,:seq_len], requires_grad=False) # variable wraps a tensor, requires_grad=False -> no backp\n",
    "        if x.is_cuda:\n",
    "            pe.cuda() # nn.Module.cuda(): moves all model parameters and buffers to the GPU\n",
    "        x = x + pe\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking and Torchtext Iterator\n",
    "\n",
    "In the encoder and decoder: To zero attention outputs wherever there is just\n",
    "padding in the input sentences.\n",
    "In the decoder: To prevent the decoder ‘peaking’ ahead at the rest of the translated\n",
    "sentence when predicting the next word\n",
    "\n",
    "we need to prevent the first output predictions from being able to see later\n",
    "into the sentence. For this we use the nopeak_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def nopeak_mask(size, opt):\n",
    "    np_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8') # np.triu: upper triangle of an array\n",
    "    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n",
    "    print('opt.device: ', opt.device)\n",
    "    if opt.device == 0:\n",
    "        np_mask = np_mask.cuda()\n",
    "    return np_mask\n",
    "\n",
    "def create_masks(src, trg, opt):\n",
    "    src_mask = (src != opt.src_pad).unsqueeze(-2) # returns new tensor with dim size one inserted at specified position\n",
    "    # unsqueeze: Negative dim will correspond to unsqueeze() applied at dim = dim + input.dim() + 1\n",
    "    if trg is not None:\n",
    "        trg_mask = (trg != opt.trg_pad).unsqueeze(-2)\n",
    "        size = trg.size(1) # get seq_len for matrix\n",
    "        np_mask = nopeak_mask(size, opt)\n",
    "        print('trg.is_cuda: ', trg.is_cuda)\n",
    "        if trg.is_cuda:\n",
    "            np_mask.cuda()\n",
    "        trg_mask = trg_mask & np_mask\n",
    "    else:\n",
    "        trg_mask = None\n",
    "    return src_mask, trg_mask\n",
    "\n",
    "# patch on Torchtext's batching process that makes it more efficient\n",
    "# from http://nlp.seas.harvard.edu/2018/04/03/attention.html#position-wise-feed-forward-networks\n",
    "\n",
    "class MyIterator(data.Iterator): # torchtext: iterator=dataloader: processing and batching of data\n",
    "    def create_batches(self):\n",
    "        if self.train:\n",
    "            def pool(d, random_shuffler):\n",
    "                for p in data.batch(d, self.batch_size * 100):\n",
    "                    p_batch = data.batch(\n",
    "                        sorted(p, key=self.sort_key),\n",
    "                        self.batch_size, self.batch_size_fn)\n",
    "                    for b in random_shuffler(list(p_batch)):\n",
    "                        yield b\n",
    "            self.batches = pool(self.data(), self.random_shuffler)\n",
    "            \n",
    "        else:\n",
    "            self.batches = []\n",
    "            for b in data.batch(self.data(), self.batch_size,\n",
    "                                          self.batch_size_fn):\n",
    "                self.batches.append(sorted(b, key=self.sort_key))\n",
    "\n",
    "global max_src_in_batch, max_tgt_in_batch\n",
    "\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization, Attention and Feed Forward\n",
    "\n",
    "We will be normalising our results between each layer in the encoder/decoder, it prevents the range of\n",
    "values in the layers changing too much\n",
    "\n",
    "Multi-headed attention layer, each input is split into multiple heads which allows the network to\n",
    "simultaneously attend to di􀁨erent subsections of each embedding.\n",
    "\n",
    "FF: This layer just consists of two linear operations, with a relu and dropout operation in\n",
    "between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "        self.size = d_model\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "    output = torch.matmul(scores, v)\n",
    "    return output\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "        # perform linear operation and split into N heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        # transpose to get dimensions bs * N * sl * d_model\n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "        return output\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
    "        super().__init__() \n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder and Decoder Layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#from Sublayers import FeedForward, MultiHeadAttention, Norm\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.ff = FeedForward(d_model, dropout=dropout)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "# build a decoder layer with two multi-head attention layers and\n",
    "# one feed-forward layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.ff = FeedForward(d_model, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, \\\n",
    "        src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder and Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We’re now ready to build the encoder and decoder:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "#from Layers import EncoderLayer, DecoderLayer\n",
    "#from Embed import Embedder, PositionalEncoder\n",
    "#from Sublayers import Norm\n",
    "import copy\n",
    "\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        x = self.embed(trg)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        #print(\"DECODER\")\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output\n",
    "\n",
    "def get_model(opt, src_vocab, trg_vocab):\n",
    "    \n",
    "    assert opt.d_model % opt.heads == 0\n",
    "    assert opt.dropout < 1\n",
    "\n",
    "    model = Transformer(src_vocab, trg_vocab, opt.d_model, opt.n_layers, opt.heads, opt.dropout)\n",
    "       \n",
    "    if opt.load_weights is not None:\n",
    "        print(\"loading pretrained weights...\")\n",
    "        model.load_state_dict(torch.load(f'{opt.load_weights}/model_weights'))\n",
    "    else:\n",
    "        for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p) \n",
    "    \n",
    "    if opt.device == 0:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "class tokenize(object):\n",
    "    \n",
    "    def __init__(self, lang):\n",
    "        self.nlp = spacy.load(lang)\n",
    "            \n",
    "    def tokenizer(self, sentence):\n",
    "        sentence = re.sub(\n",
    "        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n",
    "        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n",
    "        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n",
    "        sentence = re.sub(r\"\\,+\", \",\", sentence)\n",
    "        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n",
    "        sentence = sentence.lower()\n",
    "        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "#from Tokenize import tokenize\n",
    "#from Batch import MyIterator, batch_size_fn\n",
    "import os\n",
    "import dill as pickle\n",
    "\n",
    "def read_data(opt):\n",
    "    \n",
    "    if opt.src_data is not None:\n",
    "        try:\n",
    "            opt.src_data = open(opt.src_data).read().strip().split('\\n')\n",
    "        except:\n",
    "            print(\"error: '\" + opt.src_data + \"' file not found\")\n",
    "            quit()\n",
    "    \n",
    "    if opt.trg_data is not None:\n",
    "        try:\n",
    "            opt.trg_data = open(opt.trg_data).read().strip().split('\\n')\n",
    "        except:\n",
    "            print(\"error: '\" + opt.trg_data + \"' file not found\")\n",
    "            quit()\n",
    "\n",
    "def create_fields(opt):\n",
    "    \n",
    "    spacy_langs = ['en_core_web_sm', 'fr_core_news_sm', 'de_core_web_sm', 'es_core_web_sm', 'pt_core_web_sm', \\\n",
    "                   'it_core_web_sm', 'nl_core_web_sm']\n",
    "    if opt.src_lang not in spacy_langs:\n",
    "        print('invalid src language: ' + str(opt.src_lang) + 'supported languages : ' + str(spacy_langs))  \n",
    "    if opt.trg_lang not in spacy_langs:\n",
    "        print('invalid trg language: ' + str(opt.trg_lang) + 'supported languages : ' + str(spacy_langs))\n",
    "    \n",
    "    print(\"loading spacy tokenizers...\")\n",
    "    \n",
    "    t_src = tokenize(opt.src_lang)\n",
    "    t_trg = tokenize(opt.trg_lang)\n",
    "\n",
    "    TRG = data.Field(lower=True, tokenize=t_trg.tokenizer, init_token='<sos>', eos_token='<eos>')\n",
    "    SRC = data.Field(lower=True, tokenize=t_src.tokenizer)\n",
    "\n",
    "    if opt.load_weights is not None:\n",
    "        try:\n",
    "            print(\"loading presaved fields...\")\n",
    "            SRC = pickle.load(open(f'{opt.load_weights}/SRC.pkl', 'rb'))\n",
    "            TRG = pickle.load(open(f'{opt.load_weights}/TRG.pkl', 'rb'))\n",
    "        except:\n",
    "            print(\"error opening SRC.pkl and TXT.pkl field files, please ensure they are in \" + opt.load_weights + \"/\")\n",
    "            quit()\n",
    "        \n",
    "    return(SRC, TRG)\n",
    "\n",
    "def create_dataset(opt, SRC, TRG):\n",
    "\n",
    "    print(\"creating dataset and iterator... \")\n",
    "\n",
    "    raw_data = {'src' : [line for line in opt.src_data], 'trg': [line for line in opt.trg_data]}\n",
    "    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\"])\n",
    "    \n",
    "    mask = (df['src'].str.count(' ') < opt.max_strlen) & (df['trg'].str.count(' ') < opt.max_strlen)\n",
    "    df = df.loc[mask]\n",
    "\n",
    "    df.to_csv(\"translate_transformer_temp.csv\", index=False)\n",
    "    \n",
    "    data_fields = [('src', SRC), ('trg', TRG)]\n",
    "    train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n",
    "\n",
    "    train_iter = MyIterator(train, batch_size=opt.batchsize, device=opt.device,\n",
    "                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                        batch_size_fn=batch_size_fn, train=True, shuffle=True)\n",
    "    \n",
    "    os.remove('translate_transformer_temp.csv')\n",
    "\n",
    "    if opt.load_weights is None:\n",
    "        SRC.build_vocab(train)\n",
    "        TRG.build_vocab(train)\n",
    "        if opt.checkpoint > 0:\n",
    "            try:\n",
    "                os.mkdir(\"weights\")\n",
    "            except:\n",
    "                print(\"weights folder already exists, run program with -load_weights weights to load them\")\n",
    "                quit()\n",
    "            pickle.dump(SRC, open('weights/SRC.pkl', 'wb'))\n",
    "            pickle.dump(TRG, open('weights/TRG.pkl', 'wb'))\n",
    "\n",
    "    opt.src_pad = SRC.vocab.stoi['<pad>']\n",
    "    opt.trg_pad = TRG.vocab.stoi['<pad>']\n",
    "\n",
    "    opt.train_len = get_len(train_iter)\n",
    "\n",
    "    return train_iter\n",
    "\n",
    "def get_len(train):\n",
    "\n",
    "    for i, b in enumerate(train):\n",
    "        pass\n",
    "    \n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# code from AllenNLP\n",
    "\n",
    "class CosineWithRestarts(torch.optim.lr_scheduler._LRScheduler):\n",
    "    \"\"\"\n",
    "    Cosine annealing with restarts.\n",
    "    Parameters\n",
    "    ----------\n",
    "    optimizer : torch.optim.Optimizer\n",
    "    T_max : int\n",
    "        The maximum number of iterations within the first cycle.\n",
    "    eta_min : float, optional (default: 0)\n",
    "        The minimum learning rate.\n",
    "    last_epoch : int, optional (default: -1)\n",
    "        The index of the last epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 T_max: int,\n",
    "                 eta_min: float = 0.,\n",
    "                 last_epoch: int = -1,\n",
    "                 factor: float = 1.) -> None:\n",
    "        # pylint: disable=invalid-name\n",
    "        self.T_max = T_max\n",
    "        self.eta_min = eta_min\n",
    "        self.factor = factor\n",
    "        self._last_restart: int = 0\n",
    "        self._cycle_counter: int = 0\n",
    "        self._cycle_factor: float = 1.\n",
    "        self._updated_cycle_len: int = T_max\n",
    "        self._initialized: bool = False\n",
    "        super(CosineWithRestarts, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"Get updated learning rate.\"\"\"\n",
    "        # HACK: We need to check if this is the first time get_lr() was called, since\n",
    "        # we want to start with step = 0, but _LRScheduler calls get_lr with\n",
    "        # last_epoch + 1 when initialized.\n",
    "        if not self._initialized:\n",
    "            self._initialized = True\n",
    "            return self.base_lrs\n",
    "\n",
    "        step = self.last_epoch + 1\n",
    "        self._cycle_counter = step - self._last_restart\n",
    "\n",
    "        lrs = [\n",
    "            (\n",
    "                self.eta_min + ((lr - self.eta_min) / 2) *\n",
    "                (\n",
    "                    np.cos(\n",
    "                        np.pi *\n",
    "                        ((self._cycle_counter) % self._updated_cycle_len) /\n",
    "                        self._updated_cycle_len\n",
    "                    ) + 1\n",
    "                )\n",
    "            ) for lr in self.base_lrs\n",
    "        ]\n",
    "\n",
    "        if self._cycle_counter % self._updated_cycle_len == 0:\n",
    "            # Adjust the cycle length.\n",
    "            self._cycle_factor *= self.factor\n",
    "            self._cycle_counter = 0\n",
    "            self._updated_cycle_len = int(self._cycle_factor * self.T_max)\n",
    "            self._last_restart = step\n",
    "\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "for Windows in torchtext\\utils.py line 130:\n",
    "    #csv.field_size_limit(sys.maxsize)\n",
    "    csv.field_size_limit(2**16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 52)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m52\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "#from Models import get_model\n",
    "#from Process import *\n",
    "import torch.nn.functional as F\n",
    "#from Optim import CosineWithRestarts\n",
    "#from Batch import create_masks\n",
    "import dill as pickle\n",
    "\n",
    "def train_model(model, opt):\n",
    "    \n",
    "    print(\"training model...\")\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    if opt.checkpoint > 0:\n",
    "        cptime = time.time()\n",
    "                 \n",
    "    for epoch in range(opt.epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        if opt.floyd is False:\n",
    "            print(\"   %dm: epoch %d [%s]  %d%%  loss = %s\" %\\\n",
    "            ((time.time() - start)//60, epoch + 1, \"\".join(' '*20), 0, '...'), end='\\r')\n",
    "        \n",
    "        if opt.checkpoint > 0:\n",
    "            torch.save(model.state_dict(), 'weights/model_weights')\n",
    "                    \n",
    "        for i, batch in enumerate(opt.train):\n",
    "\n",
    "            src = batch.src.transpose(0,1)\n",
    "            trg = batch.trg.transpose(0,1)\n",
    "            trg_input = trg[:, :-1]\n",
    "            src_mask, trg_mask = create_masks(src, trg_input, opt)\n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            ys = trg[:, 1:].contiguous().view(-1)\n",
    "            opt.optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=opt.trg_pad)\n",
    "            loss.backward()\n",
    "            opt.optimizer.step()\n",
    "            if opt.SGDR == True: \n",
    "                opt.sched.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if (i + 1) % opt.printevery == 0:\n",
    "                 p = int(100 * (i + 1) / opt.train_len)\n",
    "                 avg_loss = total_loss/opt.printevery\n",
    "                 if opt.floyd is False:\n",
    "                    print(\"   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\" %\\\n",
    "                    ((time.time() - start)//60, epoch + 1, \"\".join('#'*(p//5)), \"\".join(' '*(20-(p//5))), p, avg_loss), end='\\r')\n",
    "                else:\n",
    "                    print(\"   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\" %\\\n",
    "                    ((time.time() - start)//60, epoch + 1, \"\".join('#'*(p//5)), \"\".join(' '*(20-(p//5))), p, avg_loss))\n",
    "                total_loss = 0\n",
    "            \n",
    "            if opt.checkpoint > 0 and ((time.time()-cptime)//60) // opt.checkpoint >= 1:\n",
    "                torch.save(model.state_dict(), 'weights/model_weights')\n",
    "                cptime = time.time()\n",
    "   \n",
    "   \n",
    "        print(\"%dm: epoch %d [%s%s]  %d%%  loss = %.3f\\nepoch %d complete, loss = %.03f\" %\\\n",
    "        ((time.time() - start)//60, epoch + 1, \"\".join('#'*(100//5)), \"\".join(' '*(20-(100//5))), 100, avg_loss, epoch + 1, avg_loss))\n",
    "\n",
    "#def main():\n",
    "def main():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    #parser.add_argument('-src_data', required=True)\n",
    "    #parser.add_argument('-trg_data', required=True)\n",
    "    #parser.add_argument('-src_lang', required=True)\n",
    "    #parser.add_argument('-trg_lang', required=True)\n",
    "    parser.add_argument('-src_data', default='src.txt')\n",
    "    parser.add_argument('-trg_data', default='trg.txt')\n",
    "    parser.add_argument('-src_lang', default='en_core_web_sm')\n",
    "    parser.add_argument('-trg_lang', default='fr_core_news_sm')\n",
    "    parser.add_argument('-no_cuda', action='store_true')\n",
    "    parser.add_argument('-SGDR', action='store_true')\n",
    "    parser.add_argument('-epochs', type=int, default=2)\n",
    "    parser.add_argument('-d_model', type=int, default=512)\n",
    "    parser.add_argument('-n_layers', type=int, default=6)\n",
    "    parser.add_argument('-heads', type=int, default=8)\n",
    "    parser.add_argument('-dropout', type=int, default=0.1)\n",
    "    parser.add_argument('-batchsize', type=int, default=1500)\n",
    "    parser.add_argument('-printevery', type=int, default=100)\n",
    "    parser.add_argument('-lr', type=int, default=0.0001)\n",
    "    parser.add_argument('-load_weights')\n",
    "    parser.add_argument('-create_valset', action='store_true')\n",
    "    parser.add_argument('-max_strlen', type=int, default=80)\n",
    "    parser.add_argument('-floyd', action='store_true')\n",
    "    parser.add_argument('-checkpoint', type=int, default=0)\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "    #opt = parser.parse_args(args)\n",
    "    \n",
    "    opt.device = 0 if opt.no_cuda is False else -1\n",
    "    if opt.device == 0:\n",
    "        assert torch.cuda.is_available()\n",
    "        \n",
    "    print(opt.device)\n",
    "    \n",
    "    read_data(opt)\n",
    "    SRC, TRG = create_fields(opt)\n",
    "    opt.train = create_dataset(opt, SRC, TRG)\n",
    "    model = get_model(opt, len(SRC.vocab), len(TRG.vocab))\n",
    "\n",
    "    opt.optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "    if opt.SGDR == True:\n",
    "        opt.sched = CosineWithRestarts(opt.optimizer, T_max=opt.train_len)\n",
    "\n",
    "    if opt.checkpoint > 0:\n",
    "        print(\"model weights will be saved every %d minutes and at end of epoch to directory weights/\"%(opt.checkpoint))\n",
    "    \n",
    "    if opt.load_weights is not None and opt.floyd is not None:\n",
    "        os.mkdir('weights')\n",
    "        pickle.dump(SRC, open('weights/SRC.pkl', 'wb'))\n",
    "        pickle.dump(TRG, open('weights/TRG.pkl', 'wb'))\n",
    "    \n",
    "    train_model(model, opt)\n",
    "\n",
    "    if opt.floyd is False:\n",
    "        promptNextAction(model, opt, SRC, TRG)\n",
    "\n",
    "def yesno(response):\n",
    "    while True:\n",
    "        if response != 'y' and response != 'n':\n",
    "            response = input('command not recognised, enter y or n : ')\n",
    "        else:\n",
    "            return response\n",
    "\n",
    "def promptNextAction(model, opt, SRC, TRG):\n",
    "\n",
    "    saved_once = 1 if opt.load_weights is not None or opt.checkpoint > 0 else 0\n",
    "    \n",
    "    if opt.load_weights is not None:\n",
    "        dst = opt.load_weights\n",
    "    if opt.checkpoint > 0:\n",
    "        dst = 'weights'\n",
    "\n",
    "    while True:\n",
    "        save = yesno(input('training complete, save results? [y/n] : '))\n",
    "        if save == 'y':\n",
    "            while True:\n",
    "                if saved_once != 0:\n",
    "                    res = yesno(\"save to same folder? [y/n] : \")\n",
    "                    if res == 'y':\n",
    "                        break\n",
    "                dst = input('enter folder name to create for weights (no spaces) : ')\n",
    "                if ' ' in dst or len(dst) < 1 or len(dst) > 30:\n",
    "                    dst = input(\"name must not contain spaces and be between 1 and 30 characters length, enter again : \")\n",
    "                else:\n",
    "                    try:\n",
    "                        os.mkdir(dst)\n",
    "                    except:\n",
    "                        res= yesno(input(dst + \" already exists, use anyway? [y/n] : \"))\n",
    "                        if res == 'n':\n",
    "                            continue\n",
    "                    break\n",
    "            \n",
    "            print(\"saving weights to \" + dst + \"/...\")\n",
    "            torch.save(model.state_dict(), f'{dst}/model_weights')\n",
    "            if saved_once == 0:\n",
    "                pickle.dump(SRC, open(f'{dst}/SRC.pkl', 'wb'))\n",
    "                pickle.dump(TRG, open(f'{dst}/TRG.pkl', 'wb'))\n",
    "                saved_once = 1\n",
    "            \n",
    "            print(\"weights and field pickles saved to \" + dst)\n",
    "\n",
    "        res = yesno(input(\"train for more epochs? [y/n] : \"))\n",
    "        if res == 'y':\n",
    "            while True:\n",
    "                epochs = input(\"type number of epochs to train for : \")\n",
    "                try:\n",
    "                    epochs = int(epochs)\n",
    "                except:\n",
    "                    print(\"input not a number\")\n",
    "                    continue\n",
    "                if epochs < 1:\n",
    "                    print(\"epochs must be at least 1\")\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            opt.epochs = epochs\n",
    "            train_model(model, opt)\n",
    "        else:\n",
    "            print(\"exiting program...\")\n",
    "            break\n",
    "\n",
    "    # for asking about further training use while true loop, and return\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    # python train.py -src_data path/lang1.txt -trg_data path/lang2.txt -src_lang lang1 -trg_lang lang2\n",
    "    #main(['path/lang1.txt', 'path/lang2.txt', 'lang1', 'lang2'])\n",
    "    #parser = argparse.ArgumentParser(description='Transformer training')\n",
    "    #parser.add_argument('--src_data', metavar='path', required=True, help='path text language 1')\n",
    "    #parser.add_argument('--trg_data', metavar='path', required=True, help='path to schema')\n",
    "    #parser.add_argument('--lang1', required=True, help='language 1')\n",
    "    #parser.add_argument('--lang2', required=True, help='language 2')\n",
    "    #args = parser.parse_args()\n",
    "    #main(src_data=args.src_data, trg_data=args.trg_data, lang1=args.lang1, lang2=args.lang2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (without args)\n",
    "\n",
    "use this without args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt.no_cuda:  True\n",
      "train: opt.device:  -1\n",
      "error: 'src.txt' file not found\n",
      "error: 'trg.txt' file not found\n",
      "loading spacy tokenizers...\n",
      "creating dataset and iterator... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n",
      "opt.device:  -1\n",
      "trg.is_cuda:  False\n",
      "0m: epoch 1 [####################]  100%  loss = 0.000\n",
      "epoch 1 complete, loss = 0.000\n",
      "opt.device:  -1\n",
      "trg.is_cuda:  False\n",
      "0m: epoch 2 [####################]  100%  loss = 0.000\n",
      "epoch 2 complete, loss = 0.000\n"
     ]
    }
   ],
   "source": [
    "# no-args version\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "#from Models import get_model\n",
    "#from Process import *\n",
    "import torch.nn.functional as F\n",
    "#from Optim import CosineWithRestarts\n",
    "#from Batch import create_masks\n",
    "import dill as pickle\n",
    "\n",
    "def train_model(model, opt):\n",
    "    \n",
    "    print(\"training model...\")\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    if opt.checkpoint > 0:\n",
    "        cptime = time.time()\n",
    "        \n",
    "    avg_loss = 0 # added BSC\n",
    "                 \n",
    "    for epoch in range(opt.epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        if opt.floyd is False:\n",
    "            print(\"   %dm: epoch %d [%s]  %d%%  loss = %s\" %\\\n",
    "            ((time.time() - start)//60, epoch + 1, \"\".join(' '*20), 0, '...'), end='\\r')\n",
    "        \n",
    "        if opt.checkpoint > 0:\n",
    "            torch.save(model.state_dict(), 'weights/model_weights')\n",
    "                    \n",
    "        for i, batch in enumerate(opt.train): \n",
    "\n",
    "            src = batch.src.transpose(0,1)\n",
    "            trg = batch.trg.transpose(0,1)\n",
    "            trg_input = trg[:, :-1]\n",
    "            src_mask, trg_mask = create_masks(src, trg_input, opt)\n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            ys = trg[:, 1:].contiguous().view(-1)\n",
    "            opt.optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=opt.trg_pad)\n",
    "            loss.backward()\n",
    "            opt.optimizer.step()\n",
    "            if opt.SGDR == True: \n",
    "                opt.sched.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if (i + 1) % opt.printevery == 0:\n",
    "                p = int(100 * (i + 1) / opt.train_len)\n",
    "                avg_loss = total_loss / opt.printevery\n",
    "                if opt.floyd is False:\n",
    "                    print(\"   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\" %\\\n",
    "                    ((time.time() - start)//60, epoch + 1, \"\".join('#'*(p//5)), \"\".join(' '*(20-(p//5))), p, avg_loss), end='\\r')\n",
    "                else:\n",
    "                    print(\"   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\" %\\\n",
    "                    ((time.time() - start)//60, epoch + 1, \"\".join('#'*(p//5)), \"\".join(' '*(20-(p//5))), p, avg_loss))\n",
    "                total_loss = 0\n",
    "            \n",
    "            if opt.checkpoint > 0 and ((time.time()-cptime)//60) // opt.checkpoint >= 1:\n",
    "                torch.save(model.state_dict(), 'weights/model_weights')\n",
    "                cptime = time.time()\n",
    "   \n",
    "        print(\"%dm: epoch %d [%s%s]  %d%%  loss = %.3f\\nepoch %d complete, loss = %.03f\" %\\\n",
    "        ((time.time() - start)//60, epoch + 1, \"\".join('#'*(100//5)), \"\".join(' '*(20-(100//5))), 100, avg_loss, epoch + 1, avg_loss))\n",
    "\n",
    "class optcl:\n",
    "    src_data = 'src.txt'\n",
    "    trg_data = 'trg.txt'\n",
    "    src_lang = 'en_core_web_sm'\n",
    "    trg_lang = 'fr_core_web_sm'\n",
    "    no_cuda = True\n",
    "    SGDR = True\n",
    "    epochs = 2\n",
    "    d_model = 512\n",
    "    n_layers = 6\n",
    "    heads = 8\n",
    "    dropout = 0.1\n",
    "    batchsize = 1500\n",
    "    printevery = 100\n",
    "    lr = 0.0001\n",
    "    load_weights = True\n",
    "    create_valset = True\n",
    "    max_strlen = 80\n",
    "    floyd = True\n",
    "    #train_len = 100\n",
    "    checkpoint = 10    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    #parser.add_argument('-src_data', required=True)\n",
    "    #parser.add_argument('-trg_data', required=True)\n",
    "    #parser.add_argument('-src_lang', required=True)\n",
    "    #parser.add_argument('-trg_lang', required=True)\n",
    "    parser.add_argument('-src_data', default='src.txt')\n",
    "    parser.add_argument('-trg_data', default='trg.txt')\n",
    "    parser.add_argument('-src_lang', default='en_core_web_sm')\n",
    "    parser.add_argument('-trg_lang', default='fr_core_news_sm')\n",
    "    parser.add_argument('-no_cuda', action='store_true')\n",
    "    parser.add_argument('-SGDR', action='store_true')\n",
    "    parser.add_argument('-epochs', type=int, default=2)\n",
    "    parser.add_argument('-d_model', type=int, default=512)\n",
    "    parser.add_argument('-n_layers', type=int, default=6)\n",
    "    parser.add_argument('-heads', type=int, default=8)\n",
    "    parser.add_argument('-dropout', type=int, default=0.1)\n",
    "    parser.add_argument('-batchsize', type=int, default=1500)\n",
    "    parser.add_argument('-printevery', type=int, default=100)\n",
    "    parser.add_argument('-lr', type=int, default=0.0001)\n",
    "    parser.add_argument('-load_weights')\n",
    "    parser.add_argument('-create_valset', action='store_true')\n",
    "    parser.add_argument('-max_strlen', type=int, default=80)\n",
    "    parser.add_argument('-floyd', action='store_true')\n",
    "    parser.add_argument('-checkpoint', type=int, default=0)\n",
    "\n",
    "    #opt = parser.parse_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    #opt = parser.parse_args(['-src_data=src.txt', '-trg_data=trg.txt', '-src_lang=en_core_web_sm', \\\n",
    "                            # '-trg_lang=fr_core_web_sm', '-no_cuda=store_true', '-SGDR=True', \\\n",
    "                            #'-epochs=2', '-d_model=512', '-n_layers=6' \\\n",
    "                            #'-heads=8', '-dropout=0.1', '-batchsize=1500' \\\n",
    "                            #'-printevery=100', '-lr=0.0001', '-load_weights=True' \\\n",
    "                            #'-create_valset=True', '-max_strlen=80', '-floyd=True' \\\n",
    "                            #'-checkpoint=0'])\n",
    "    \n",
    "    opt.no_cuda = True\n",
    "    print('opt.no_cuda: ', opt.no_cuda)\n",
    "    opt.device = 0 if opt.no_cuda is False else -1\n",
    "    if opt.device == 0:\n",
    "        assert torch.cuda.is_available()\n",
    "    print('train: opt.device: ', opt.device)\n",
    "    \n",
    "    read_data(opt)\n",
    "    SRC, TRG = create_fields(opt)\n",
    "    opt.train = create_dataset(opt, SRC, TRG)\n",
    "    model = get_model(opt, len(SRC.vocab), len(TRG.vocab))\n",
    "\n",
    "    opt.optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "    if opt.SGDR == True:\n",
    "        opt.sched = CosineWithRestarts(opt.optimizer, T_max=opt.train_len)\n",
    "\n",
    "    if opt.checkpoint > 0:\n",
    "        print(\"model weights will be saved every %d minutes and at end of epoch to directory weights/\"%(opt.checkpoint))\n",
    "    \n",
    "    if opt.load_weights is not None and opt.floyd is not None:\n",
    "        os.mkdir('weights')\n",
    "        pickle.dump(SRC, open('weights/SRC.pkl', 'wb'))\n",
    "        pickle.dump(TRG, open('weights/TRG.pkl', 'wb'))\n",
    "    \n",
    "    train_model(model, opt)\n",
    "\n",
    "    if opt.floyd is False:\n",
    "        promptNextAction(model, opt, SRC, TRG)\n",
    "\n",
    "def yesno(response):\n",
    "    while True:\n",
    "        if response != 'y' and response != 'n':\n",
    "            response = input('command not recognised, enter y or n : ')\n",
    "        else:\n",
    "            return response\n",
    "\n",
    "def promptNextAction(model, opt, SRC, TRG):\n",
    "\n",
    "    saved_once = 1 if opt.load_weights is not None or opt.checkpoint > 0 else 0\n",
    "    \n",
    "    if opt.load_weights is not None:\n",
    "        dst = opt.load_weights\n",
    "    if opt.checkpoint > 0:\n",
    "        dst = 'weights'\n",
    "\n",
    "    while True:\n",
    "        save = yesno(input('training complete, save results? [y/n] : '))\n",
    "        if save == 'y':\n",
    "            while True:\n",
    "                if saved_once != 0:\n",
    "                    res = yesno(\"save to same folder? [y/n] : \")\n",
    "                    if res == 'y':\n",
    "                        break\n",
    "                dst = input('enter folder name to create for weights (no spaces) : ')\n",
    "                if ' ' in dst or len(dst) < 1 or len(dst) > 30:\n",
    "                    dst = input(\"name must not contain spaces and be between 1 and 30 characters length, enter again : \")\n",
    "                else:\n",
    "                    try:\n",
    "                        os.mkdir(dst)\n",
    "                    except:\n",
    "                        res= yesno(input(dst + \" already exists, use anyway? [y/n] : \"))\n",
    "                        if res == 'n':\n",
    "                            continue\n",
    "                    break\n",
    "            \n",
    "            print(\"saving weights to \" + dst + \"/...\")\n",
    "            torch.save(model.state_dict(), f'{dst}/model_weights')\n",
    "            if saved_once == 0:\n",
    "                pickle.dump(SRC, open(f'{dst}/SRC.pkl', 'wb'))\n",
    "                pickle.dump(TRG, open(f'{dst}/TRG.pkl', 'wb'))\n",
    "                saved_once = 1\n",
    "            \n",
    "            print(\"weights and field pickles saved to \" + dst)\n",
    "\n",
    "        res = yesno(input(\"train for more epochs? [y/n] : \"))\n",
    "        if res == 'y':\n",
    "            while True:\n",
    "                epochs = input(\"type number of epochs to train for : \")\n",
    "                try:\n",
    "                    epochs = int(epochs)\n",
    "                except:\n",
    "                    print(\"input not a number\")\n",
    "                    continue\n",
    "                if epochs < 1:\n",
    "                    print(\"epochs must be at least 1\")\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            opt.epochs = epochs\n",
    "            train_model(model, opt)\n",
    "        else:\n",
    "            print(\"exiting program...\")\n",
    "            break\n",
    "\n",
    "    # for asking about further training use while true loop, and return\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "#from Models import get_model\n",
    "#from Process import *\n",
    "import torch.nn.functional as F\n",
    "#from Optim import CosineWithRestarts\n",
    "#from Batch import create_masks\n",
    "import pdb\n",
    "import dill as pickle\n",
    "import argparse\n",
    "#from Models import get_model\n",
    "#from Beam import beam_search\n",
    "from nltk.corpus import wordnet\n",
    "from torch.autograd import Variable\n",
    "import re\n",
    "\n",
    "def get_synonym(word, SRC):\n",
    "    syns = wordnet.synsets(word)\n",
    "    for s in syns:\n",
    "        for l in s.lemmas():\n",
    "            if SRC.vocab.stoi[l.name()] != 0:\n",
    "                return SRC.vocab.stoi[l.name()]\n",
    "            \n",
    "    return 0\n",
    "\n",
    "def multiple_replace(dict, text):\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text) \n",
    "\n",
    "def translate_sentence(sentence, model, opt, SRC, TRG):\n",
    "    \n",
    "    model.eval()\n",
    "    indexed = []\n",
    "    sentence = SRC.preprocess(sentence)\n",
    "    for tok in sentence:\n",
    "        if SRC.vocab.stoi[tok] != 0 or opt.floyd == True:\n",
    "            indexed.append(SRC.vocab.stoi[tok])\n",
    "        else:\n",
    "            indexed.append(get_synonym(tok, SRC))\n",
    "    sentence = Variable(torch.LongTensor([indexed]))\n",
    "    if opt.device == 0:\n",
    "        sentence = sentence.cuda()\n",
    "    \n",
    "    sentence = beam_search(sentence, model, SRC, TRG, opt)\n",
    "\n",
    "    return  multiple_replace({' ?' : '?',' !':'!',' .':'.','\\' ':'\\'',' ,':','}, sentence)\n",
    "\n",
    "def translate(opt, model, SRC, TRG):\n",
    "    sentences = opt.text.lower().split('.')\n",
    "    translated = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        translated.append(translate_sentence(sentence + '.', model, opt, SRC, TRG).capitalize())\n",
    "\n",
    "    return (' '.join(translated))\n",
    "\n",
    "\n",
    "def main(*args):\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-load_weights', required=True)\n",
    "    parser.add_argument('-k', type=int, default=3)\n",
    "    parser.add_argument('-max_len', type=int, default=80)\n",
    "    parser.add_argument('-d_model', type=int, default=512)\n",
    "    parser.add_argument('-n_layers', type=int, default=6)\n",
    "    parser.add_argument('-src_lang', required=True)\n",
    "    parser.add_argument('-trg_lang', required=True)\n",
    "    parser.add_argument('-heads', type=int, default=8)\n",
    "    parser.add_argument('-dropout', type=int, default=0.1)\n",
    "    parser.add_argument('-no_cuda', action='store_true')\n",
    "    parser.add_argument('-floyd', action='store_true')\n",
    "    \n",
    "    opt = parser.parse_args(args)\n",
    "\n",
    "    opt.device = 0 if opt.no_cuda is False else -1\n",
    " \n",
    "    assert opt.k > 0\n",
    "    assert opt.max_len > 10\n",
    "\n",
    "    SRC, TRG = create_fields(opt)\n",
    "    model = get_model(opt, len(SRC.vocab), len(TRG.vocab))\n",
    "    \n",
    "    while True:\n",
    "        opt.text =input(\"Enter a sentence to translate (type 'f' to load from file, or 'q' to quit):\\n\")\n",
    "        if opt.text==\"q\":\n",
    "            break\n",
    "        if opt.text=='f':\n",
    "            fpath =input(\"Enter a sentence to translate (type 'f' to load from file, or 'q' to quit):\\n\")\n",
    "            try:\n",
    "                opt.text = ' '.join(open(opt.text, encoding='utf-8').read().split('\\n'))\n",
    "            except:\n",
    "                print(\"error opening or reading text file\")\n",
    "                continue\n",
    "        phrase = translate(opt, model, SRC, TRG)\n",
    "        print('> '+ phrase + '\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from Batch import nopeak_mask\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "def init_vars(src, model, SRC, TRG, opt):\n",
    "    \n",
    "    init_tok = TRG.vocab.stoi['<sos>']\n",
    "    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "    e_output = model.encoder(src, src_mask)\n",
    "    \n",
    "    outputs = torch.LongTensor([[init_tok]])\n",
    "    if opt.device == 0:\n",
    "        outputs = outputs.cuda()\n",
    "    \n",
    "    trg_mask = nopeak_mask(1, opt)\n",
    "    \n",
    "    out = model.out(model.decoder(outputs,\n",
    "    e_output, src_mask, trg_mask))\n",
    "    out = F.softmax(out, dim=-1)\n",
    "    \n",
    "    probs, ix = out[:, -1].data.topk(opt.k)\n",
    "    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0)\n",
    "    \n",
    "    outputs = torch.zeros(opt.k, opt.max_len).long()\n",
    "    if opt.device == 0:\n",
    "        outputs = outputs.cuda()\n",
    "    outputs[:, 0] = init_tok\n",
    "    outputs[:, 1] = ix[0]\n",
    "    \n",
    "    e_outputs = torch.zeros(opt.k, e_output.size(-2),e_output.size(-1))\n",
    "    if opt.device == 0:\n",
    "        e_outputs = e_outputs.cuda()\n",
    "    e_outputs[:, :] = e_output[0]\n",
    "    \n",
    "    return outputs, e_outputs, log_scores\n",
    "\n",
    "def k_best_outputs(outputs, out, log_scores, i, k):\n",
    "    \n",
    "    probs, ix = out[:, -1].data.topk(k)\n",
    "    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1) + log_scores.transpose(0,1)\n",
    "    k_probs, k_ix = log_probs.view(-1).topk(k)\n",
    "    \n",
    "    row = k_ix // k\n",
    "    col = k_ix % k\n",
    "\n",
    "    outputs[:, :i] = outputs[row, :i]\n",
    "    outputs[:, i] = ix[row, col]\n",
    "\n",
    "    log_scores = k_probs.unsqueeze(0)\n",
    "    \n",
    "    return outputs, log_scores\n",
    "\n",
    "def beam_search(src, model, SRC, TRG, opt):\n",
    "    \n",
    "\n",
    "    outputs, e_outputs, log_scores = init_vars(src, model, SRC, TRG, opt)\n",
    "    eos_tok = TRG.vocab.stoi['<eos>']\n",
    "    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "    ind = None\n",
    "    for i in range(2, opt.max_len):\n",
    "    \n",
    "        trg_mask = nopeak_mask(i, opt)\n",
    "\n",
    "        out = model.out(model.decoder(outputs[:,:i],\n",
    "        e_outputs, src_mask, trg_mask))\n",
    "\n",
    "        out = F.softmax(out, dim=-1)\n",
    "    \n",
    "        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, opt.k)\n",
    "        \n",
    "        ones = (outputs==eos_tok).nonzero() # Occurrences of end symbols for all input sentences.\n",
    "        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long).cuda()\n",
    "        for vec in ones:\n",
    "            i = vec[0]\n",
    "            if sentence_lengths[i]==0: # First end symbol has not been found yet\n",
    "                sentence_lengths[i] = vec[1] # Position of first end symbol\n",
    "\n",
    "        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n",
    "\n",
    "        if num_finished_sentences == opt.k:\n",
    "            alpha = 0.7\n",
    "            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n",
    "            _, ind = torch.max(log_scores * div, 1)\n",
    "            ind = ind.data[0]\n",
    "            break\n",
    "    \n",
    "    if ind is None:\n",
    "        length = (outputs[0]==eos_tok).nonzero()[0]\n",
    "        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[0][1:length]])\n",
    "    \n",
    "    else:\n",
    "        length = (outputs[ind]==eos_tok).nonzero()[0]\n",
    "        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[ind][1:length]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SRC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8768fa04828d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#src_vocab = len(EN_TEXT.vocab)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#trg_vocab = len(FR_TEXT.vocab)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msrc_vocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSRC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrg_vocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTRG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SRC' is not defined"
     ]
    }
   ],
   "source": [
    "d_model = 512\n",
    "heads = 8\n",
    "N = 6\n",
    "#src_vocab = len(EN_TEXT.vocab)\n",
    "#trg_vocab = len(FR_TEXT.vocab)\n",
    "src_vocab = SRC.vocab\n",
    "trg_vocab = TRG.vocab\n",
    "model = Transformer(src_vocab, trg_vocab, d_model, N, heads)\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "# this code is very important! It initialises the parameters with a\n",
    "# range of values that stops the signal fading or getting too big.\n",
    "# See this blog for a mathematical explanation.\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, print_every=100):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    start = time.time()\n",
    "    temp = start\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "       \n",
    "        for i, batch in enumerate(train_iter):\n",
    "            src = batch.English.transpose(0,1)\n",
    "            trg = batch.French.transpose(0,1)\n",
    "            # the French sentence we input has all words except\n",
    "            # the last, as it is using each word to predict the next\n",
    "            \n",
    "            trg_input = trg[:, :-1]\n",
    "            \n",
    "            # the words we are trying to predict\n",
    "            \n",
    "            targets = trg[:, 1:].contiguous().view(-1)\n",
    "            \n",
    "            # create function to make masks using mask code above\n",
    "            \n",
    "            src_mask, trg_mask = create_masks(src, trg_input)\n",
    "            \n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            \n",
    "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)),\n",
    "            results, ignore_index=target_pad)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            total_loss += loss.data[0]\n",
    "            if (i + 1) % print_every == 0:\n",
    "                loss_avg = total_loss / print_every\n",
    "                print(\"time = %dm, epoch %d, iter = %d, loss = %.3f, %ds per %d iters\" % ((time.time() - start) // 60,\n",
    "                epoch + 1, i + 1, loss_avg, time.time() - temp,\n",
    "                print_every))\n",
    "                total_loss = 0\n",
    "                temp = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
